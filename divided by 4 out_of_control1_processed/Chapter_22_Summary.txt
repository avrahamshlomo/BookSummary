The article is about the difficulty of predicting the future and the importance of prediction as a form of control for complex adaptive systems. The author visits Doyne Farmer, a renowned scientist who is starting a company to predict stock prices with computer simulations. Farmer explains that prediction is based on models built from experiential data, rather than elementary physics equations. He uses the example of an outfielder's empirically-based "theory" of missiles to illustrate the evolvability of such models. The article suggests that although predicting the future is difficult, it is essential for complex systems to preadapt and control their destiny. The article discusses the unpredictability of chaotic systems, using the example of a balloon's flight path. While the path is nonlinear and almost unsolvable, a teenager could learn to catch the balloon better than chance by molding a theory based on data. Similarly, vivisystems, such as stock markets, are unpredictable due to their recursive field of causality, but the whole system can make approximate guesses about the future. Chartists have had modest success in predicting currency markets using simple linear equations, but with the rise of cheap, industrial-strength computers, forecasters can extract reliable patterns from the nonlinearity behind financial prices to make profitable bets. The article discusses the role of "rocket scientists" or mathematicians in deciphering the complexities of high-dimensional systems, such as stock prices, weather, and ecosystems. While these systems may seem unpredictable, chaos theory suggests that short-term predictability is possible. Chaos theory is not the same as randomness, and there is order in chaos. Doyne Farmer, a former mathematical physicist and pioneer in chaos theory, emphasizes the importance of understanding the complexities of high-dimensional systems. Farmer and his colleagues founded a commune of nerd hippies in the 1970s, investigating the physics of seemingly random generating devices. In 1977, a group called the Santa Cruz Chaos Cabal built microcomputers into the soles of shoes to predict the toss of a roulette ball. The code was based on the physics of the wheel, and the system predicted a small neighbourhood of numbers where the ball was likely to land. The group sold the system to other gamblers, but it was unreliable due to the hardware. The experience taught the founder, Farmer, three lessons: patterns in chaotic systems can be used to make predictions, you don't need to look far ahead to make a useful prediction, and even a little bit of information about the future can be valuable. Farmer and five other physicists founded a start-up called the Prediction Company to crack Wall Street using high-powered computers, experimental nonlinear dynamics, and other esoteric techniques. They would create a system that could predict the future of the financial market a few days ahead and gamble millions of dollars. The Santa Fe Institute's recent research suggests that "seeing further is not seeing better" when dealing with real-world complexity. Tiny errors caused by limited information compound into grievous errors when extended too far into the future, and the cost of dealing with exponentially increasing numbers of error-tainted possibilities is not worth the trouble. The researchers used chess-playing computer programs as the test-bed for their forecasting work and found that neither Deep Thought nor human grandmasters need to look very far ahead to play excellent games. This limited look-ahead is called "positive myopia." Generally, grandmasters survey the chess board and forecast the pieces only one move ahead. Common sense embodies a "positive myopia" and suggests that we use rules of thumb or rough guidelines to compensate for insufficient information and make decisions. Prediction machinery need not see like a prophet to be of use. The Prediction Company, founded by a group of mathematicians and physicists, aims to exploit the flip side of chaos by detecting patterns in the stock market. They believe that there are "pockets of predictability" within complex systems that can be exploited for financial gain. The company's scientists use a combination of old and new techniques to search for patterns in financial data in real time, with the goal of finding any exploitable order within the apparent complexity of the market. Their approach is based on their experience with chaos theory and their faith in the existence of local predictability, despite the skepticism of most economists. The Prediction Company, founded by Norman Packard and Doyne Farmer, uses algorithms to detect patterns in market chaos and make predictions based on them. The company's models are built using inductive reasoning, and they do not concern themselves with the causes of the patterns they detect. Instead, they focus on recognizing order and exploiting it. Before a model is used to bet with, it is tested using backcasting techniques, and if it can accurately predict the outcome based on past data, it is considered successful. The Prediction Company's financial backers get exclusive use of the algorithms in exchange for payments based on performance. The company faces competition from other firms, including Citibank, which also uses algorithms to predict market moves. The Prediction Company, founded by David Shaw, uses computer neural nets to build models of high-flying stocks. The system juggles the weight of each influence to better fit the data, rewarding the best combinations to produce better guesses. The neural net system keeps feeding the results back in to hone its guess in a type of learning. Successful traders detect patterns, then make an internal model in order to make predictions, sharpening the feedback loop. Prediction machinery is ultimately theory-making machinery, devices for generating abstractions and generalizations. Prediction machinery is found in biology, too. Intelligence and smartness in general is fundamentally prediction machinery. The article discusses the development of prediction and simulation machinery, particularly in the areas of financial markets and military simulations. The author interviews John Henry, a former farmer turned financial trader, who aims to produce prediction machinery that can predict various phenomena, including financial markets, weather, global climate, and epidemics. Henry's company has reportedly achieved success in predicting markets using "computerized intuition." The article also describes the development of swarm computing, a decentralized, massively parallel computing system that was used to speed up a computer simulation of a tank battle. The article notes that a simulation of a desert war between Iraq and Kuwait was accidentally chosen as a test scenario by the Jet Propulsion Lab, which caused some discomfort for the lab during the Gulf War. The US military has been using war-gaming simulations for decades to predict and prepare for potential conflicts. These simulations are created by small departments at military schools and training centers, supported by academics and think tanks. The nerve center for US military operations is Central Command in Florida, which had traditionally focused on a superpower game where the only worthy opponent was the Soviet Union. However, General Norman Schwarzkopf refocused attention on alternative scenarios, including a Mid-East desert war along the border of Iraq. In 1989, Gary Ware and his team at Central Command began modeling a war based on Schwarzkopf's hunches, compiling data to create a simulated desert war called Operation Internal Look. The simulation was based on collecting a hundred thousand details about current forces in the Mid-East, compiling optical laser disc maps of the entire Gulf area, and transferring the territory onto a CD to feed into the main computerized war-gaming simulator. In July 1990, Saddam Hussein invaded Kuwait, and Ware's simulation forecast a fairly brief thirty-day war if the US and Saudi Arabia were to strike back. When word of the prescient simulation surfaced, Ware came out smelling like roses. The article discusses the use of war gaming simulations in predicting the outcome of the Gulf War. The simulations showed that airpower would be the key to success and that if airpower could inflict the predicted results, US ground forces would not sustain heavy losses. This led to a heavy air campaign, which ultimately proved successful. The simulations predicted greater resistance from the Iraqis than they actually gave, and the war moved so fast that daily modeled forecasts were not necessary. The article then questions the idea of using predictive technology to forecast the future of human society, citing the historical inaccuracy of cultural predictions. The article argues that while long-term predictions are often wrong, short-term predictions for complex systems are not only possible but essential. The human ability to forecast aspects of society, economy, and technology will steadily increase, despite the strangeness that dependable predictions will have on present actions. The article identifies three pockets of predictability in the greater web of human interactions: invariants, growth curves, and cyclic waves. Invariants are behaviors that change very little over time, and tracing an invariant optimization point can often alert us to a clean pocket of predictability. Growth curves are universal characteristics of growing things, and they can be used to predict short-term changes. Cyclic waves are periodic fluctuations in complex systems that can be predicted by analyzing past data. Overall, the article suggests that while long-term predictions may be unreliable, short-term predictions for complex systems are feasible and becoming more so with advancements in technology. The article discusses three modes of prediction: chaos theory, S-curves, and cyclic waves. Chaos theory suggests that small changes in initial conditions can lead to vastly different outcomes, but certain systems exhibit patterns that can be predicted. S-curves show that natural growth follows a strict law, and once a phenomenon is on a roll, a numerical snapshot of its history can be taken and flipped over to predict its eventual limits and demise. Cyclic waves suggest that primary environmental cycles trigger many secondary and tertiary internal cycles, and uncovering fragments of these cycles can be used to predict pockets of behavior. The article also mentions financial chartists who attempt to extract longwave patterns from past stock market prices, and while they were once ridiculed for their approach, recent studies have shown that their methods often work. The article discusses two approaches to predicting stock markets: chartism and fundamentalism. Chartists use patterns in market data to predict future trends, while fundamentalists seek to understand the underlying dynamics of the market. The article argues that both approaches have their merits, but chartism is more effective in the short term. However, predicting the stock market is difficult because it is built on expectations, and accurate predictions do not necessarily lead to financial gain. The article also explores the concept of feedback control, which involves using past performance to inform future decisions. This can be achieved through traditional feedback loops or through sense organs that pick up information from the future. Life arose on a planet with transparent air and water, allowing organisms to develop prediction machinery to anticipate future events and adapt to changing environments. Similarly, the digitization of human activity and the creation of a transparent medium through data circulation allows for the development of predictive machinery, such as the ability to see patterns in financial data or anticipate the course of a battle. Complex systems, including humans, tell themselves stories of the future, and the ability to anticipate is fundamental to survival and adaptation. In the 1970s, the first global spreadsheet was created by Jay Forrester, an engineer at MIT, to model the world's economic, population, and resource systems. The model, called World Dynamics, was improved upon by Forrester and his associate Dennis Meadows, who published it as Limits to Growth. The simulation, filled with real data, was the first of its kind and warned that humanity's current path would lead to civilization's collapse. The model was successful in alerting the world to the dangers of environmental degradation and the need for sustainable practices. The Limits to Growth model predicted that if current growth trends continued, the planet's limits would be reached within the next 100 years. The model generated quantifiable results and was highly controversial, but raised the discussion of resources and human activity to a necessary planetary scale. The model was less successful in spawning better predictive models and was mistrusted, but ironically, it remains the only visible world model. The model runs on a software program called Stella and is woven out of an impressive web of "stocks" and "flows" that form a spaghetti maze of loops, subloops, and cross-loops that constitute the entire world. The model has both strengths and weaknesses, including narrow overall scenarios. The success or failure of this prominent attempt can teach much about using models to predict extremely complex adaptive systems. The Limits to Growth model explores a narrow set of assumptions and ignores scenarios based on unreasonable assumptions. Even the best model can be sidetracked by false premises, which can lead to adjustments of the basic nature of the model. The model lacks room for learning and adaptation, which is necessary for a genuinely predictive model. In real life, people adapt based on their own immediate learning cycle and act out of immediate self-interest. The learning must be modeled as an internal loop residing within the model, and the assumptions must be adaptable. The model assumes fixed values for fluctuating values, but in reality, the assumptions themselves have coevolutionary mechanisms that flux over time. The Limits to Growth model, which predicts the collapse of human society due to resource depletion and pollution, has limitations that undermine its validity. The model homogenizes the world and ignores the importance of geography and locality. It also cannot model open-ended growth, which is necessary for a reliable prediction of future growth. The model is inherently incapable of generating open-ended growth and collapses in nearly every initial condition. The model cannot mimic the emergence of the industrial revolution from the agrarian age or take the world from the industrial revolution to whatever follows next beyond that. The model requires intervention from modelers to make changes to save it. A better world model should possess the dynamics to transform itself to the next level on its own. Human intelligence is necessary to perceive the whole situation and make changes in the human societal structure. The Limits to Growth simulation, created by Forrester and Meadows, attempted to model the complex adaptive system of human infrastructure on Earth. However, the model's inadequacies highlighted the limits of certain simulations, and a real predictive model of a planetary society must incorporate distributed learning, local and regional variation, and increasing complexification. The model must possess a "requisite complexity" to keep up with the complexity of the modeled system. Feedback circuits are important for control and self-governance, but they are insufficient to breed the behaviors of the most interesting vivisystems. The dream of Meadows and others is to create a system that mirrors the real evolving world, but this requires a more flexible and informed approach. The book discusses two additional types of complexity required for the full spectrum of vivisystem character: distributed being and open-ended evolution. The key insight is that a system needs a flexible structure to evolve into something new. Direct feedback models can achieve stabilization, but they cannot learn, grow or diversify, which are essential complexities for a model of changing culture or life. However, importing evolution and learning requires exporting control, which is impossible in self-making systems like vivisystems. The direction of large swarm-like systems like human society is controlled by a messy multitude of interconnecting, self-contradictory agents. No one is in charge, but we are all steering, and we can learn to anticipate what is immediately ahead.