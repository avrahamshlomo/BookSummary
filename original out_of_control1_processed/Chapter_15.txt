ARTIFICIAL EVOLUTION 
The first time Tom Ray released his tiny hand-made creature 
into his computer, it reproduced rapidly until hundreds of copies 
occupied the available memory space. Ray's creature was an experimental computer virus of sorts; it wasn't dangerous because the bugs couldn't replicate outside his computer. The idea was to see what would happen if they had to compete against each other in a confined world. 
Ray cleverly devised his universe so that out of the thousands of clones from 
the first ancestral virus, about ten percent replicated with small variations. The initial creature was an "80"-so named because it had 80 bytes of code. A number of 80s "flipped a bit" at random and became creatures 79 or 81 bytes long. Some of these new mutant viruses soon took over Ray's virtual world. In turn, they mutated into further varieties. Creature 80 was nearly overwhelmed to the point of extinction by the mushrooming ranks of new "organisms." But the 80s never completely died, and long after the new arrivals 79, 51, and 45 emerged and peaked in population, the 80s rebounded.
After a few hours of operation, Tom Ray's electric-powered evolution 
machine had evolved a soup of nearly a hundred types of computer viruses, all battling it out for survival in his isolated world. On his very first try, after months of writing code, Ray had brewed artificial evolution.
When he was a shy, soft-spoken Harvard undergraduate, Ray had collected 
ant colonies in Costa Rica for the legendary ant-man, E. O. Wilson. Wilson needed live leafcutting ant colonies for his Cambridge labs. Ray hired on in the lush tropics of Central America to locate and capture healthy colonies in the field, and then ship them to Harvard. He found that he was particularly good at the task. The trick was to dig into the jungle soil with the deftness of a surgeon in order to remove the guts of a colony. What was needed was the intact inner chamber of the queen's nest, along with the queen herself, her nurse ants, and a mini-ant-garden stocked with enough food to support the chamber for shipping. A young newborn colony was perfect. The heart of such a colony might fit into a tea cup. That was the other essential trick: to locate a really small nest hidden under the natural camouflaged debris of the forest floor. From a minuscule core that could be warmed in one's hands, the colony could grow in a few years to fill a large room.While collecting ants in the rain forest, Ray discovered a obscure species of 
butterfly that would tag along the advancing lines of army ants. The army ants' ruthless eating habits-devouring any animal life in their path-would flush a cloud of flying insects eager to get out of the way. A kind of bird evolved to follow the pillaging army, happily picking off the agitated fleeing insects in the air. The butterfly, in turn, followed the birds who followed the army ants. The butterflies tagged along to feast on the droppings of the ant-birds-a much needed source of nitrogen for egg laying. The whole motley crew of ants, ant-birds and ant-bird-butterflies, and who knew what else, would roam across the jungle like a band of gypsies in cahoots.
Ray was overwhelmed by such wondrous complexity. Here was an entirely 
nomadic community! Most attempts to understand ecological relations seemed laughable in light of these weird creations. How in the universe did these three groups of species (one ant, three butterflies, and about a dozen birds) ever wind up in this peculiar codependency? And why?
By the time he had finished his Ph.D., Ray felt that the science of ecology 
was moribund because it could not offer a satisfying answer to such big questions. Ecology lacked good theories to generalize the wealth of observations piling up from every patch of wilderness. It was stymied by extensive local knowledge: without an overarching theory, ecology was merely a library of fascinating just-so stories. The life cycles of barnacle communities, or the seasonal pattern of buttercup fields, or behavior of bobcat clans were all known, but what principles, if any, guided all three? Ecology needed a science of complexity that addressed the riddles of form, history, development-all the really interesting questions-yet was supported by field data. 
Along with many other biologists, Ray felt that the best hope for ecology was 
to shift its focus from ecological time (the thousand-year lifetime of a forest) to evolutionary time (the million-year lifetime of a tree species). Evolution at least had a theory. Yet, the study of evolution too was caught up with the same fixation on specifics. "I was frustrated," Ray told me, "because I didn't want to study the products of evolution-vines and ants and butterflies. I wanted to study evolution itself."
Tom Ray dreamed of making an electric-powered evolution machine. With a 
black box that contained evolution he could demonstrate the historical principles of ecology, how a rain forest descends from earlier woods, and how in fact ecologies emerge from the same primordial forces that spawn species. If he could develop an evolution engine, he'd have a test-bed with which to do real ecological experiments. He could take a community and run it over and over again in different combinations, making ponds without algae, woods without termites, grasslands without gophers, or just to cover the bases, jungles with gophers and grasslands with algae. He could start with viruses and see where it all would lead him.Ray was a bird watcher, insect collector, plantsman-the farthest thing from a 
computer nerd-yet he was sure such a machine could be built. He remembered a moment ten years earlier when he was learning the Japanese game of Go from an MIT hacker who used biological metaphors to explain the rules. As Ray tells it, "He said to me, 'Do you know that it is possible to write a computer program that can self-replicate?' And right at that moment I imagined all the things I'm doing now. I asked him how to do it, and he said, 'Oh, it's trivial,' but I didn't remember what he said, or whether in fact he actually knew. When I remembered that conversation I stopped reading novels and started reading computer manuals."
Ray's solution to the problem of making an electronic evolution machine was 
to start with simple replicators and give them a cozy habitat and plenty of energy and places to fill. The closest real things to these creatures were bits of self-replicating RNA. But the challenge seemed doable. He would cook up a soup of computer viruses.
About this time in 1989, the news magazines were chock-full of cover stories 
pronouncing computer viruses worse than the plague and as evil as technology could get. Yet Ray saw in the simple codes of computer viruses the beginnings of a new science: experimental evolution and ecology. 
To protect the outside world (and to keep his own computer from crashing), 
Ray devised a virtual computer to contain his experiments. A virtual computer is a bit of clever software that emulates a pretend computer deep within the operating subconscious of the real computer. By containing his tiny bits of replicating code inside this shadow computer, Ray sealed them from the outside world and gave himself room to mess with vital functions, such as computer memory, without jeopardizing the integrity of his host computer. "After a year of reading computer manuals, I sat down and wrote code. In two months the thing was running. And in the first two minutes of running without a crash, I had evolving creatures."
Ray seeded his world (which he called "Tierra") with a single creature he 
programmed by hand-the 80-byte creature-inserted into a block of RAM in his virtual computer. The 80 creature reproduced by finding an empty RAM block 80 bytes big and then filling it with a copy of itself. Within minutes the RAM was saturated with copies of 80.
But Ray had added two key features that modified this otherwise Xerox-like 
copying machine into an evolution machine: his program occasionally scrambled the digital bits during copying, and he assigned his creatures a priority tag for an executioner. In short he introduced variation and death.
Computer scientists had told him that if he randomly varied bits of a 
computer code (which is all his creatures really are), the resulting programs would break and then crash the computer. They felt that the probability of getting a working program by randomly introducing bugs into code was so low as to make his scheme a waste of time. This sentiment seemed in line 
with what Ray knew about the fragile perfection needed to keep computers going; bugs killed progress. But because his creature programs would run in his shadow computer, whenever a mutation would birth a creature that was seriously broken, his executioner program-he named it "the Reaper"-would kill it while the rest of his Tierra world kept running. In essence, Tierra spotted the buggy programs that couldn't reproduce and yanked them out of the virtual computer.
Yet, the Reaper would pass over the very rare mutants that worked, that is, 
those that happened to form a bona fide alternative program. These legitimate variations could multiply and breed other variants. If you ran Tierra for a billion computer cycles or so, as Ray did, a startling number of randomly generated creatures formed during those billion chances. And just to keep the pot boiling, Ray also assigned creatures an age stamp so that older creatures would die. "The Reaper kills either the oldest creature or the most screwed-up creature," Ray says with a smile. 
On Ray's first run of Tierra, random variation, death, and natural selection 
worked. Within minutes Ray witnessed an ecology of newly created creatures emerge to compete for computer cycles. The competition rewarded creatures of smaller size since they needed less cycles, and in Darwinian ruthlessness, terminated the greedy consumers, the infirm, and the old. Creature 79 (one byte smaller than 80) was lucky. It worked productively and soon outpaced the 80s. 
Ray also found something very strange: a viable creature with only 45 very 
efficient bytes which overran all other creatures. "I was amazed how fast this system would optimize," Ray recalls. "I could graph its pace as the system would generate organisms surviving on shorter and shorter genomes." 
On close examination of 45's code, Ray was amazed to discover that it was a 
parasite. It contained only a part of the code it needed to survive. In order to reproduce, it "borrowed" the reproductive section from the code of an 80 and copied itself. As long as there were enough 80 hosts around, the 45s thrived. But if there were too many 45s in the limited world, there wouldn't be enough 80s to supply copy resources. As the 80s waned, so did the 45s. The pair danced the classic coevolutionary tango, back and forth endlessly, just like populations of foxes and rabbits in the north woods.
"It seems to be a universal property of life that all successful systems attract 
parasites," Ray reminds me. In nature parasites are so common that hosts soon coevolve immunity to them. Then eventually the parasites coevolve strategies to circumvent that immunity. And eventually the hosts coevolve defenses to repel them again. In reality, these actions are not alternating steps but two constant forces pressing against one another. Ray learned to run ecological experiments in Tierra using parasites. He 
loaded his "soup" with 79s which he suspected were immune to the 45 parasite. They were. But as the 79s prospered, a second parasite evolved that could prey on them. This one was 51 bytes long. When Ray sequenced its genes he found that a single genetic event had transformed a 45 into a 51. "Seven instructions of unknown origin," Ray says, "had replaced one instruction somewhere near the middle of the 45," transforming a disabled parasite into a newly potent one. And so it went. A new creature evolved that was immune to 51s, and so on.
Poking around in the soups of long runs, Ray discovered parasites that 
preyed on other parasites-hyperparasites: "Hyperparasites are like neighbors who steal power from your lines to the power plant. You sit in the dark while they use your power and you pay the bill." In Tierra, organisms such as the 45s discovered that they didn't need to carry a lot of code around to replicate themselves because their environment was full of code-of other organisms. Quips Ray, "It's just like us using other animals' amino acids [when we eat them]." On further inspection Ray found hyper-hyperparasites thriving, parasites raised to the third. He found "social cheaters"-creatures that exploit the code of two cooperating hyperparasites (the "cooperating" hyperparasites were stealing from each other!). Social cheaters require a fairly well developed ecology. They can't be seen yet, but there are probably hyper-hyper-hyperparasites and no end to elaborate freeloading games possible in his world.

And Ray found creatures that surpassed the programming skills of human 
software engineers.
"I started with a creature 80 bytes large," Ray remembers, "because that's 
the best I could come up with. I figured that maybe evolution could get it down to 75 bytes or so. I let the program run overnight and the next morning there was a creature-not a parasite, but a fully self-replicating creature-that was only 22 bytes! I was completely baffled how a creature could manage to self-replicate in only 22 instructions without stealing instructions from others, as parasites do. To share this novelty, I distributed its basic algorithm onto the Net. A computer science student at MIT saw my explanation, but somehow didn't get the code of the 22 creature. He tried to recreate it by hand, but the best he could do was get it to 31 instructions. He was quite distressed when he found out I came up with 22 instructions in my sleep!"
What humans can't engineer, evolution can. Ray puts it nicely as he shows 
off a monitor with traces of the 22s propagating in his soup: "It seems utterly preposterous to think that you could randomly alter a computer program and get something better than what you carefully crafted by hand, but here's living proof." It suddenly dawns on the observer that there is no end to the creativity that these mindless hackers can come up with. 
Because creatures consume computer cycles, there is an advantage to 
smaller (shorter sets of instructions) creatures. Ray reprogrammed Tierra's code so the system assigned computer resources to creatures in proportion to their size; large ones getting more cycles. In this mode, Ray's creatures inhabited a size-neutral world, which seemed more suited for long runs since it wasn't biased to either the small or large. Once Ray ran a size-neutral world for 15 billion cycles of his computer. Somewhere around 11 billion cycles, a diabolically clever 36 creature evolved. It calculated its true size, then behind its back so to speak, shifted all the bits in the measurement to the left one bit, which in binary code is equal to doubling the number. So by lying about its size, creature 36 sneakily garnered the resources of a 72 creature, which meant that it got twice the usual CPU time. Naturally this mutation swept through the system.
Perhaps the most astounding thing about Tom Ray's electrically powered evolution machine is that it created sex. Nobody told it about sex, but it 
found it nonetheless. In an experiment to see what would happen if he turned the mutation function off, Ray let the soup run without deliberate error. He was flabbergasted to discover that even without programmed mutation, evolution pushed forward.
In real natural life, sex is a much more important source of variation than 
mutations. Sex, at the conceptual level, is genetic recombination-a few genes from Dad and a few genes from Mom combined into a new genome for Junior. Sometimes in Tierra a parasite would be in the middle of asexual reproduction, "borrowing" the copy function of some other creature's code, when the Reaper would happen to kill the host midway in the process. When this happens the parasite uses some copy code of the new creature born in the old creature's space, and part of the "dead" creature's interrupted reproduction function. The resultant junior was a wild, new recombination created without deliberate mutation. (Ray also says this weird reproduction "amounts to sex with the dead!") Interrupted sex had happened all the time in his soup, but only when Ray turned off his "flip-a-bit" mutator did he notice its results. It turned out that inadvertent recombination alone was enough to fuel evolution. There was sufficient irregularity in the moment of death, and where creatures lived in RAM, that this complexity furnished the variety that evolution required. In one sense, the system evolved variation.
To scientists, the most exhilarating news to come out of Ray's artificial 
evolution machine is that his small worlds display what seems to be punctuated equilibrium. For relatively long periods of time, the ratio of populations remain in a steady tango of give and take with only the occasional extinction or birth of a new species. Then, in a relative blink, this equilibrium is punctuated by a rapid burst of roiling change with many newcomers and eclipsing of the old. For a short period change is rampant. Then things sort out and stasis and equilibrium reigns again. The current interpretation of fossil evidence on Earth is that this pattern predominates in nature. Stasis is the norm; change occurs in bouts. The same punctuated equilibrium pattern has been seen in other evolutionary computer models as well, such as Kristian Lindgren's coevolutionary Prisoner's Dilemma world. If artificial evolution mirrors organic evolution, one has to wonder what would happen if Ray let his world run forever? Would his viral creatures invent multicellularity?
Unfortunately, Ray has never turned his world on marathon mode just to see 
what would happen over months or years. He's still fiddling with the program, gearing it up to collect the immense store of data (50 megabytes per day) such a marathon run would generate. He admits that "sometimes we're like a bunch of boys with a car. We've always got the hood up and pieces of the engine out on the garage floor, but we hardly ever drive the car because we're too interested in souping it up." 
In fact, Ray has his sights fixed on a new piece of hardware, a technology 
that ought to be. Ray figures that he could take his virtual computer and the fundamental language he wrote for it and "burn" it into a computer chip-a 
slice of silicon that did evolution. This off-the-shelf Darwin Chip would then be a module you could plug into any computer, and it would breed stuff for you, fast. You could evolve lines of computer code, or subroutines, or maybe even entire software programs. "I find it rather peculiar," Ray confides, "that as a tropical plant ecologist I'm now designing computers." 
The prospects that a Darwin Chip might serve up are delicious. Imagine you 
have one in your PC where you use Microsoft Word as a word processor. With resident Darwinism loaded into your operating system, Word would evolve as you worked. It would use your computer's idle CPU cycles to improve, and learn, in a slow evolutionary way, to fit itself to your working habits. Only those alterations that improved the speed or the accuracy would survive. However Ray feels strongly that messy evolution should happen away from the job. "You want to divorce evolution from the end user," he says. He imagines "digital husbandry" happening offline in back rooms, so to speak, so that the common failures necessary for evolution are never seen by its customer. Before an evolving application is turned over to an end user, it is "neutered" so that it can't evolve while in use.
Retail evolution is not so farfetched. Today you can buy a spreadsheet 
module that does something similar in software. It's called, naturally enough, "Evolver." Evolver is a template for spreadsheets on the Macintosh-very complicated spreadsheets spilling over with hundreds of variables and "what-if" functions. Engineers and database specialists use it. 
Let's say you have the medical records of thirty thousand patients. You'd 
probably like to know what a typical patient looks like. The larger the database, the harder it is to see what you have in there. Most software can do averaging, but that does not extract a "typical" patient. What you would like to know is what set of measurements-out of the thousands of categories collected by the records-have similar values for the maximum number of people? It's a problem of optimizing huge numbers of interacting variables. The task is familiar to any living species: how does it maximize the results of thousands of variables? Raccoons have to ensure their own survival, but there are a thousand variables (foot size, night vision, heart rate, skin color, etc.) that can be changed over time, and altering one parameter will alter another. The only way to tread through this vast space of possible answers, and retain some hope of reaching a peak, is by evolution.
The Evolver software optimizes the broadest possible profile for the largest 
number of patients by trying a description of a typical patient, then testing how many fit that description, then tweaking the profile in a multitude of directions to see if more patients fit it, and then varying, selecting, and varying again, until a maximum number of patients fit the profile. It's a job particularly suited for evolution. 
"Hill climbing," computer scientists call the process. Evolutionary programs 
attempt to scale the peak in the libraries of form where the optimal solution resides. By relentlessly pushing the program toward better solutions, the 
programs climb up until they can't climb any higher. At that point, they are on a peak-a maximum-of some sort. The question always is: is their summit the tallest peak around, or is the program stuck on a local peak adjacent to a much taller peak across the valley, with no way to retreat?
Finding a solution-a peak-is not difficult. What evolution in nature and 
evolutionary programs in computers excel at is hill climbing to global summits-the highest peaks around-when the terrain is rugged with many false summits.

John Holland is a gnomic figure of indeterminate age who once worked on 
the world's earliest computers, and who now teaches at the University of 
Michigan. He was the first to invent a mathematical method of describing evolution's optimizing ability in a form that could be easily programmed on a computer. Because of the way his math mimicked the effects of genetic information, Holland called them genetic algorithms, or GAs for short.
Holland, unlike Tom Ray, started with sex. Holland's genetic algorithms took two strings of DNA-like computer code that did a job fairly well and recombined the two at random in a sexual swap to see if the new offspring code might do a little better. In designing his system, Holland had to overcome the same looming obstacle that Ray faced: any random generation of a computer program would most likely produce not a program that was either slightly better or slightly worse, but one that was not sensible at all. Statistically, successive random mutations to a working code were bound to produce successive crashes.
Mating rather than mutating was discovered by theoretical biologists in the 
early 1960s to make a more robust computer evolution-one that birthed a higher ratio of sensible entities. But sexual mating alone was too restrictive in what it could come up with. In the mid-1960s Holland devised his GAs; these relied chiefly on mating and secondarily on mutation as a background instigator. With sex and mutation combined, the system was both flexible and wide.
Like many other systems thinkers, Holland sees the tasks of nature and the 
job of computers as similar. "Living organisms are consummate problem solvers," Holland wrote in a summary of his work. "They exhibit a versatility that puts the best computer programs to shame. This observation is especially galling for computer scientists, who may spend months or years of intellectual effort on an algorithm, whereas organisms come by their abilities through the apparently undirected mechanism of evolution and natural selection."
The evolutionary approach, Holland wrote, "eliminates one of the greatest 
hurdles in software design: specifying in advance all the features of a problem." Anywhere you have many conflicting, interlinked variables and a broadly defined goal where the solutions may be myriad, evolution is the 
answer.
Just as evolution deals in populations of individuals, genetic algorithms 
mimic nature by evolving huge churning populations of code, all processing and mutating at once. GAs are swarms of slightly different strategies trying to simultaneously hill-climb over a rugged landscape. Because a multitude of code strings "climb" in parallel, the population visits many regions of the landscape concurrently. This ensures it won't miss the Big Peak.
Implicit parallelism is the magic by which evolutionary processes guarantee 
you climb not just any peak but the tallest peak. How do you locate the global optima? By testing bits of the entire landscape at once. How do you optimally balance a thousand counteracting variables in a complex problem? By sampling a thousand combinations at once. How do you develop an organism that can survive harsh conditions? By running a thousand slightly varied individuals at once.
In Holland's scheme, the highest performing bits of code anywhere on the 
landscape mate with each other. Since high performance increases the assigned rate of mating in that area, this focuses the attention of the genetic algorithm system on the most promising areas in the overall landscape. It also diverts computational cycles away from unpromising areas. Thus parallelism sweeps a large net over the problem landscape while reducing the number of code strings that need manipulating to locate the peaks. 
Parallelism is one of the ways around the inherent stupidity and blindness of 
random mutations. It is the great irony of life that a mindless act repeated in sequence can only lead to greater depths of absurdity, while a mindless act performed in parallel by a swarm of individuals can, under the proper conditions, lead to all that we find interesting.
John Holland invented genetic algorithms while studying the mechanics of 
adaptation in the 1960s. His work was ignored until the late 1980s by all but a dozen wild-eyed computer grad students. A couple of other researchers, such as the engineers Lawrence Fogel and Hans Bremermann, independently played around with mechanical evolution of populations in the 1960s; they enjoyed equal indifference from the science community. Michael Conrad, a computer scientist now at Wayne State University, Michigan, also drifted from the study of adaptation to modeling evolving populations in computers in the 1970s, and met the same silence that Holland did a decade earlier. The totality of this work was obscure to computer science and completely unknown in biology. 
No more than a couple of students wrote theses on GA until Holland's book 
Adaptation in Natural and Artificial Systems about GAs and evolution appeared in 1975. The book sold only 2500 copies until it was reissued in 1992. Between 1972 and 1982, no more than two dozen articles on GAs were published in all of science. You could not even say computational 
evolution had a cult following.
The lack of interest from biology was understandable (but not 
commendable); biologists reasoned that nature was far too complex to be meaningfully represented by computers of that time. The lack of interest from computer science is more baffling. I was often perplexed in my research for this book why such a fundamental process as computational evolution could be so wholly ignored? I now believe the disregard stems from the messy parallelism inherent in evolution and the fundamental conflict it presented to the reigning dogma of computers: the von Neumann serial program.
The first functioning electronic computer was the ENIAC, which was booted 
up in 1945 to solve ballistic calculations for the U.S. Army. The ENIAC was an immense jumble of 18,000 hot vacuum tubes, 70,000 resistors, and 10,000 capacitors. The instructions for the machine were communicated to it by setting 6,000 switches by hand and then turning the program on. In essence the machine calculated all its values simultaneously in a parallel fashion. It was a bear to program.
The genius von Neumann radically altered this awkward programming 
system for the EDVAC, the ENIAC's successor and the first general-purpose computer with a stored program. Von Neumann had been thinking about systemic logic since the age of 24 when he published his first papers (in 1927) on mathematical logic systems and game theory. Working with the EDVAC computer group, he invented a way to control the slippery calculations needed to program a machine that could solve more than one problem. Von Neumann proposed that a problem be broken into discrete logical steps, much like the steps in a long division problem, and that intermediate values in the task be stored temporarily in the computer in such a way that those values could be considered input for the next portion of the problem. By feeding back the calculation through a coevolutionary loop (or what is now called a subroutine), and storing the logic of the program in the machine so that it could interact with the answer, von Neumann was able to take any problem and turn it into a series of steps that could be comprehended by a human mind. He also invented a notation for describing this step-wise circuit: the now familiar flow chart. Von Neumann's serial architecture for computation-where one instruction at a time was executed-was amazingly versatile and extremely suited to human programming. He published the general outlines for the architecture in 1946, and it immediately became the standard for every commercial computer thereafter, without exception.
In 1949, John Holland worked on Project Whirlwind, a follow-up to the 
EDVAC. In 1950 he joined the logical design team on what was then called IBM's Defense Calculator, later to become the IBM 701, the world's first commercial computer. Computers at that point were room-size calculators consuming a lot of electricity. But in the mid-fifties Holland participated in the legendary circle of thinkers who began to map out the possibility of 
artificial intelligence.
While luminaries such as Herbert Simon and Alan Newall thought of learning 
as a noble, high-order achievement, Holland thought of it as a polished type of lowly adaptation. If we could understand adaptation, especially evolutionary adaptation, Holland believed, we might be able to understand and maybe imitate conscious learning. But although the others could appreciate the parallels between evolution and learning, evolution was the low road in a fast-moving field.
Browsing for nothing in particular in the University of Michigan math library 
in 1953, Holland had an epiphany. He stumbled upon a volume, The Genetical Theory of Natural Selection, written by R. A. Fisher in 1929. It was Darwin who led the consequential shift from thinking about creatures as individuals to thinking about populations of individuals, but it was Fisher who transformed this population-thinking into a quantitative science. Fisher took what appeared to be a community of flittering butterflies evolving over time and saw them as a whole system transmitting differentiated information in parallel through a population. And he worked out the equations that governed that diffusion of information. Fisher single-handedly opened a new world of human knowledge by subjugating nature's most potent force-evolution-with humankind's most potent tool-mathematics. "That was the first time I realized that you could do significant mathematics on evolution," Holland recalled of the encounter. "The idea appealed to me tremendously." Holland was so enamored of treating evolution as a type of math that in a desperate attempt to get a copy of the out-of-print text (in the days before copiers) he begged the library (unsuccessfully) to sell it to him. Holland absorbed Fisher's vision and then leaped to a vision of his own: butterflies as coprocessors in a field of computer RAM. 
Holland felt artificial learning at its core was a special case of adaptation. He 
was pretty sure he could implement adaptation on computers. Taking the insights of Fisher-that evolution was a class of probability-Holland began the job of trying to code evolution into a machine.
Very early in his efforts, he confronted the dilemma that evolution is a 
parallel processor while all available electronic computers were von Neumann serial processors. 
In his eagerness to wire up a computer as a platform for evolution, Holland 
did the only reasonable thing: he designed a massively parallel computer to run his experiments. During parallel computing, many instructions are executed concurrently, rather than one at a time. In 1959 he presented a paper which, as its title says, describes "A Universal Computer Capable of Executing an Arbitrary Number of Sub-programs Simultaneously," a contraption that became known as a "Holland Machine." It was almost thirty years before one was built.In the interim, Holland and the other computational evolutionists had to rely 
on serial computers to grow evolution. By various tricks they programmed their fast serial CPUs to simulate a slow parallelism. The simulations worked well enough to hint at the power of true parallelism.

It wasn't until the mid-1980s that Danny Hillis began building the first 
massively parallel computer. Just a few years earlier Hillis had been a 
wunderkind computer science student. His pranks and hacks at MIT were legendary, even on the campus that invented hacking. With his usual clarity, Hillis summed up for writer Steven Levy the obstacle the von Neumann bottleneck had become in computers: "The more knowledge you gave them, the slower computers got. Yet with a person, the more knowledge you give him, the faster he gets. So we were in this paradox that if you tried to make computers smart, they got stupider." 
Hillis really wanted to be a biologist, but his knack for understanding 
complex programs drew him to the artificial intelligence labs of MIT, where he wound up trying to build a thinking computer "that would be proud of me." He attributes to John Holland the seminal design notions for a swarmy, thousand-headed computing beast. Eventually Hillis led a group that invented the first parallel processing computer, the Connection Machine. In 1988 it sold for a cool $1 million apiece, fully loaded. Now that the machines are here, Hillis has taken up computational biology in earnest. 
"There are only two ways we know of to make extremely complicated 
things," says Hillis. "One is by engineering, and the other is evolution. And of the two, evolution will make the more complex." If we can't engineer a computer that will be proud of us, we may have to evolve it.
Hillis's first massively parallel Connection Machine had 64,000 processors 
working in unison. He couldn't wait to get evolution going. He inoculated his computer with a population of 64,000 very simple software programs. As in Holland's GA or in Ray's Tierra, each individual was a string of symbols that could be altered by mutation. But in Hillis's Connection Machine, each program had an entire computer processor dedicated to running it. The population, therefore, would react extremely quickly and in numbers that were simply not possible for serial computers to handle.
Each bug in his soup was initially a random sequence of instructions, but 
over tens of thousands of generations they became a program that sorted a long string of numbers into numerical order. Such a sort routine is an integral part of most larger computer programs; over the years many hundreds of man hours have been spent in computer science departments engineering the most efficient sort algorithms. Hillis let thousands of his 
sorters proliferate in his computer, mutate at random, and occasionally sexually swap genes. Then in the usual evolutionary maneuver, his system tested them and terminated the less fit so that only the shortest (the best) sorting programs would be given a chance to reproduce. Over ten thousand generations of this cycle, his system bred a software program that was nearly as short as the best sorting programs written by human programmers. 
Hillis then reran the experiment but with this important difference: He 
allowed the sorting test itself to mutate while the evolving sorter tried to solve it. The string of symbols in the test varied to become more complicated in order to resist easy sorting. Sorters had to unscramble a moving target, while tests had to resist a moving arrow. In effect Hillis transformed the test list of numbers from a harsh passive environment into an active organism. Like foxes and hares or monarchs and milkweed, sorters and tests got swept up by a textbook case of coevolution. 
A biologist at heart, Hillis viewed the mutating sorting test as a parasitic 
organism trying to disrupt the sorter. He saw his world as an arms race-parasite attack, host defense, parasite counterattack, host counter-defense, and so on. Conventional wisdom claimed such locked arms races are a silly waste of time or an unfortunate blind trap to get stuck in. But Hillis discovered that rather than retard the advance of the sorting organisms, the introduction of a parasite sped up the rate of evolution. Parasitic arms races may be ugly, but they turbocharged evolution. 
Just as Tom Ray would discover, Danny Hillis also found that evolution can 
surpass ordinary human skills. Parasites thriving in the Connection Machine prodded sorters to devise a solution more efficient than the ones they found without parasites. After 10,000 cycles of coevolution, Hillis's creatures evolved a sorting program previously unknown to computer scientists. Most humbling, it was only a step short of the all-time shortest algorithm engineered by humans. Blind dumb evolution had designed an ingenious, and quite useful, software program.
A single processor in the Connection Machine is very stupid. It might be as 
smart as an ant. On its own, a single processor could not come up with an original solution to anything, no matter how many years it spent. Nor would it come up with much if 64,000 processors were strung in a row.
But 64,000 dumb, mindless, ant-brains wired up into a vast interconnected 
network become a field of evolving populations and, at the same time, look like a mass of neurons in a brain. Out of this network of dumbness emerge brilliant solutions to problems that tax humans. This "order-emerging-out-of-massive-connections" approach to artificial intelligence became known as "connectionism."Connectionism rekindled earlier intuitions that evolution and learning were 
deeply related. The connectionists who were reaching for artificial learning latched onto the model of vast webs interconnecting dumb neurons, and then took off with it. They developed a brand of connected concurrent processing-running in either virtual or hardwired parallel computers-that performed simultaneous calculations en masse, similar to genetic algorithms but with more sophisticated (smarter) accounting systems. These smartened up networks were called neural networks. So far neural nets have achieved only limited success in generating partial "intelligence," although their pattern-recognition abilities are useful.
But that anything at all emerges from a field of lowly connections is 
startling. What kind of magic happens inside a web to give it an almost divine power to birth organization from dumb nodes interconnected, or breed software from mindless processors wired to each other? What alchemic transformation occurs when you connect everything to everything? One minute you have a mob of simple individuals, the next, after connection, you have useful, emergent order. 
There was a fleeting moment when the connectionists imagined that perhaps 
all you needed to produce reason and consciousness was a sufficiently large field of interlinked neurons out of which rational intelligence would assemble itself. That dream vanished as soon as they tried it.
But in an odd way, the artificial evolutionists still pursue the dream of 
connectionism. Only they, in sync with the slow pace of evolution, would be more patient. But it is the slow, very slow, pace of evolution that bothers me. I put my concern to Tom Ray this way: "What worries me about off-the-shelf evolution chips and parallel evolutionary processing machines is that evolution takes an incredible amount of time. Where is this time going to come from? Look at the speed at which nature is working. Consider all the little molecules that have just been snapped together as we talk here. Nature is incredibly speedy and vast and humongously parallel, and here we are going to try to beat it. It seems to me there's simply not enough time to do it.
Ray replied: "Well, I worry about that too. On the other hand, I'm amazed at 
how fast evolution has occurred in my system with only one virtual processor churning it. Besides, time is relative. In evolution, a generation sets the time scale. For us a generation is thirty years, but for my creatures it is a fraction of a second. And, when I play god I can crank up the global mutation rate. I'm not sure, but I may be able to get more evolution on a computer." 
There are other reasons for doing evolution in a computer. For instance, Ray 
can record the sequence of every creature's genome and keep a complete demographic and genealogic record of every creature's birth and death. It produces an avalanche of data that is impossible to compile in the real world. And though the complexity and cost of extracting the information will surge as the complexity of the artificial worlds surge, it will probably remain 
easier to do than in the unwired organic world. As Ray told me, "Even if my world gets as complex as the real world, I'm god. I'm omniscient. I can get information on whatever attracts my attention without disturbing it, without walking around crushing plants. That's a crucial difference."

Back in the 18th century, Benjamin Franklin had a hard time convincing 
his friends that the mild electrical currents produced in his lab were identical 
in their essence to the thundering lightning that struck in the wild. The difference in scale between his artificially produced microsparks and the sky-splitting, tree-shattering, monstrous bolts generated in the heavens was only part of the problem. Primarily, observers found it unnatural that Franklin could re-create nature, as he claimed.
Today, Tom Ray has trouble convincing his colleagues that the evolution he 
has synthesized in his lab is identical in essence to the evolution shaping the animals and plants in nature. The difference in time scale between the few hours his world has evolved and the billions of years wild nature has evolved is only part of the problem. Primarily, skeptics find it unnatural that Ray can re-create such an intangible and natural process as he claims.
Two hundred years after Franklin, artificially generated lightning-tamed, 
measured, and piped through wires into buildings and tools-is the primary organizing force in our society, particularly our digital society. Two hundred years from now, artificial adaptation-tamed, measured and piped into every type of mechanical apparatus we have-will become the central organizing force in our society. 
No computer scientist has yet synthesized an artificial intelligence-as 
desirable and immensely powerful and life-changing as that would be. Nor has any biochemist created an artificial life. But evolution captured, as Ray and others have done, and re-created on demand, is now seen by many technicians as the subtle spark that can create both our dreams of artificial life and artificial intelligence, unleashing their awesome potential. We can grow rather than make them.
We have built machines as complicated as is possible with unassisted 
engineering. The kind of projects we now have on the drawing boards-software programs reckoned in tens of millions of lines of code, communication systems spanning the planet, factories that must adapt to rapidly shifting global buying habits and retool in days, cheap Robbie the Robots-all demand a degree of complexity that only evolution can coordinate.Because it is slow, invisible, and diffuse, evolution has the air of a hardly 
believable ghost in this fast-paced, in-your-face world of humanmade machines. But I prefer to think of evolution as a natural technology that is easily moved into computer code. It is this supercompatibility between evolution and computers that will propel artificial evolution into our digital lives.

Artificial evolution is not merely confined to silicon, however. Evolution 
will be imported wherever engineering balks. Synthetic evolution technology 
is already employed in the frontier formerly called bioengineering.
Here's a real-world problem. You need a drug to combat a disease whose 
mechanism has just been isolated. Think of the mechanism as a lock. All you need is the right key molecule-a drug-that triggers the active binding sites of the lock. 
Organic molecules are immensely complex. They consist of thousands of 
atoms that can be arranged in billions of ways. Simply knowing the chemical ingredients of a protein does not tell us much about its structure. Extremely long chains of amino acids are folded up into a compact bundle so that the hot spots-the active sites of the protein-are held on the outside at just the right position. Folding a protein is similar to the task of pushing a mile-long stretch of string marked in blue at six points, and trying to fold the string up into a bundle so that the six points of blue all land on different outside faces of the bundle. There are uncountable ways you could proceed, of which only a very few would work. And usually you wouldn't know which sequence was even close until you had completed most of it. There is not enough time in the universe to try all of the variations.
Drug makers have had two traditional manners for dealing with this 
complexity. In the past, pharmacists relied on hit or miss. They tried all existing chemicals found in nature to see if any might work on a given lock. Often, one or two natural compounds activated a couple of sites-a sort of partial key. But now in the era of engineering, biochemists try to decipher the pathways between gene code and protein folding to see if they can engineer the sequence of steps needed to create a molecular shape. Although there has been some limited success, protein folding and genetic pathways are still far too complex to control. Thus this logical approach, called "rational drug design," has bumped the ceiling of how much complexity we can engineer.
Beginning in the late 1980s, though, bioengineering labs around the world 
began perfecting a new procedure that employs the only other tool we have for creating complex entities: evolution. In brief, the evolutionary system generates billions of random molecules 
which are tested against the lock. Out of the billion humdrum candidates, one molecule contains a single site that matches one of, say, six sites on the lock. That partial "warm" key sticks to the lock and is retained. The rest are washed down the drain. Then, a billion new variations of that surviving warm key are made (retaining the trait that works) and tested against the lock. Perhaps another warm key is found that now has two sites correct. That key is kept as a survivor while the rest die. A billion variations are made of it, and the most fit of that generation will survive to the next. In less than ten generations of repeating the wash/mutate/bind sequence, this molecular breeding program will find a drug-perhaps a lifesaving drug-that keys all the sites of the lock.
Almost any kind of molecule might be evolved. An evolutionary biotechnician 
could evolve an improved version of insulin, say, by injecting insulin into a rabbit and harvesting the antibodies that the rabbit's immune system produced in reaction to this "toxin." (Antibodies are the complementary shape to a toxin.) The biotechnician then puts the extracted insulin antibodies into an evolutionary system where the antibodies serve as a lock against which new keys are tested. After several generations of evolution, he would have a complementary shape to the antibody, or in effect, an alternative working shape to the insulin shape. In short, he'd have another version of insulin. Such an alternative insulin would be extremely valuable. Alternative versions of natural drugs can offer many advantages: they might be smaller; more easily delivered in the body; produce fewer side effects; be easier to manufacture; or be more specific in their targets.
Of course, the bioevolutionists could also harvest an antibody against, say, a 
hepatitis virus and then evolve an imitation hepatitis virus to match the antibody. Instead of a perfect match, the biochemist would select for a surrogate molecule that lacked certain activation sites that cause the disease's fatal symptoms. We call this imperfect, impotent surrogate a vaccine. So vaccines could also be evolved rather than engineered.
All the usual reasons for creating drugs lend themselves to the evolutionary 
method. The resulting molecule is indistinguishable from rationally designed drugs. The only difference is that while an evolved drug works, we have no idea of how or why it does so. All we know is that we gave it a thorough test and it passed. Cloaked from our understanding, these invented drugs are "irrationally designed." 
Evolving drugs allows a researcher to be stupid, while evolution slowly 
accumulates the smartness. Andrew Ellington, an evolutionary biochemist at Indiana University, told Science that in evolving systems "you let the molecule tell you about itself, because it knows more about itself than you do." 
Breeding drugs would be a medical boon. But if we can breed software and 
then later turn the system upon itself so that software breeds itself, leading to who knows what, can we set molecules too upon the path of open-ended 
evolution?
Yes, but it's a difficult job. Tom Ray's electric-powered evolution machine is 
heavy on the heritable information but light on bodies. Molecular evolution programs are heavy on bodies but skimpy on heritable information. Naked information is hard to kill, and without death there is no evolution. Flesh and blood greatly assist the cause of evolution because a body provides a handy way for information to die. Any system that can incorporate the two threads of heritable information and mortal bodies has the ingredients for an evolutionary system.
Gerald Joyce, a biochemist at San Diego whose background is the chemistry of very early life, devised a simple way to incorporate the dual nature of information and bodies into one robust artificial evolutionary system. He accomplished this by recreating a probable earlier stage of life on Earth-"RNA world"-in a test tube.
RNA is a very sophisticated molecular system. It was not the very first living 
system, but life on Earth at some stage almost certainly became RNA life. Says Joyce, "Everything in biology points to the fact that 3.9 billion years ago, RNA was running the show."
RNA has a unique advantage that no other system we know about can 
boast. It acts at once as both body and info, phenotype and genotype, messenger and message. An RNA molecule is at once the flesh that must interact in the world and the information that must inherit the world, or at least be transmitted to the next generation. Though limited by this uniqueness, RNA is a wonderfully compact system in which to begin open-ended artificial evolution.
Gerald Joyce runs a modest group of graduates and postdocs at Scripps 
Institute, a sleek modern lab along the California coast near San Diego. His experimental RNA worlds are tiny drops that pool in the bottom of plastic micro-test tubes hardly the volume of thimbles. At any one time dozens of these pastel-colored tubes, packed in ice in styrofoam buckets, await being warmed up to body temperature to start evolving. Once warmed, RNA will produce a billion copies in one hour. 
"What we have here," Joyce says pointing to one of the tiny tubes, "is a 
huge parallel processor. One of the reasons I went into biology instead of doing computer simulations of evolution is that no computer on the face of the Earth, at least for the near future, can give me 1015 microprocessors in parallel." The drops in the bottom of the tubes are about the size of the smart part of computer chips. Joyce polishes the image: "Actually, our artificial system is even better than playing with natural evolution because there aren't too many natural systems that come close to letting us turn over 1015 individuals in a hour, either." 
In addition to the intellectual revolution a self-sustaining life system would 
launch, Joyce sees evolution as a commercially profitable way to create useful chemicals and drugs. He imagines molecular evolution systems that run 24 hours, 365 days a year: "You give it a task, and say don't come out of your closet until you've figured out how to convert molecule A to molecule B."
Joyce rattles off a list of biotech companies that are today dedicated solely 
to research in directed molecular evolution (Gilead, Ixsys, Nexagen, Osiris, Selectide, and Darwin Molecule). His list does not include established biotech companies, such as Genentech, which are doing advanced research into directed evolutionary techniques, but which also practice rational drug design. Darwin Molecule, whose principal patent holder is complexity researcher Stuart Kauffman, raised several million dollars to exploit evolution's power to design drugs. Manfred Eigen, Nobel Prize-winning biochemist, calls directed evolution "the future of biotechnology." 
But is this really evolution? Is this the same vital spirit that brought us 
insulin, eyelashes, and raccoons in the first place? It is. "We approach evolution with a capital D for Darwin," Joyce told me. "But since the selection pressure is determined by us, rather than nature, we call this directed evolution."
Directed evolution is another name for supervised learning, another name 
for the Method of traversing the Library, another name for breeding. Instead of letting the selection emerge, the breeder directs the choice of varieties of dogs, pigeons, pharmaceuticals, or graphic images.

David Ackley is a researcher of neural nets and genetic algorithms at 
Bellcore, the R&D labs for the Baby Bells. Ackley has some of the most 
original ways of looking at evolutionary systems that I've come across.
Ackley is a bear of a guy with a side-of-the-mouth wisecracking delivery. He broke up 250 serious scientists at the 1990 Second Artificial Life Conference with a wickedly funny video of a rather important artificial life world he and colleague Michael Littman had made. His "creatures" were actually bits of code not too different from a classical GA, but he dressed them up with moronic smiley faces as they went about chomping each other or bumping into walls in his graphical world. The smart survived, the dumb died. As others had, Ackley found that his world was able to evolve amazingly fit organisms. Successful individuals would live Methuselahian lifetimes-25,000 day-steps in his world. These guys had the system all figured out. They knew how to get what they needed with minimum effort. And how to stay out of trouble. Not only would individuals live long, but the populations that shared their genes would survive eons as well.
Noodling around with the genes of these streetwise creatures, Ackley 
uncovered a couple of resources they hadn't taken up. He saw that he could improve their chromosomes in a godlike way to exploit these resources, making them even better adapted to the environment he had set up for them. So in an early act of virtual genetic engineering, he modified their evolved code and set them back again into his world. As individuals, they were superbly fitted and flourished easily, scoring higher on the fitness scale than any creatures before them.
But Ackley noticed that their population numbers were always lower than the 
naturally evolved guys. As a group they were anemic. Although they never died out, they were always endangered. Ackley felt their low numbers wouldn't permit the species to last more than 300 generations. So while handcrafted genes suited individuals to the max, they lacked the robustness of organically grown genes, which suited the species to the max. Here, in the home-brewed world of a midnight hacker, was the first bit of testable proof for hoary ecological wisdom: that what is best for an individual ain't necessarily best for the species."It's tough accepting that we can't figure out what's best in the long run," 
Ackley told the Artificial Life conference to great applause, "but, hey, I guess that's life!"
Bellcore allowed Ackley to pursue his microgod world because they 
recognized that evolution is a type of computation. Bellcore was, and still is, interested in better computational methods, particularly those based on distributed models, because ultimately a telephone network is a distributed computer. If evolution is a useful type of distributed computation, what might some other methods be? And what improvements or variations, if any, can we make to evolutionary techniques? Taking up the usual library/space metaphor, Ackley gushes, "The space of computational machinery is unbelievably vast and we have only explored very tiny corners of it. What I'm doing, and what I want to do more of, is to expand the space of what people recognize as computation."
Of all the possible types of computation, Ackley is primarily interested in 
those procedures that underpin learning. Strong learning methods require smart teachers; that's one type of learning. A smart teacher tells a learner what it should know, and the learner analyzes the information and stores it in memory. A less smart teacher can also teach by using a different method. It doesn't know the material itself, but it can tell when the learner guesses the right answer-as a substitute teacher might grade tests. If the learner guesses a partial answer the weak teacher can give a hint of "getting warm," or "getting cold" to help the learner along. In this way, a weaker teacher can potentially generate information that it itself doesn't own. Ackley has been pushing the edge of weak learning as a way of maximizing computation: leveraging the smallest amount of information in, to get the maximum information out. "I'm trying to come up with the dumbest, least informative teacher as possible," Ackley told me. "And I think I found it. My answer is: death."
Death is the only teacher in evolution. Ackley's mission was to find out: what 
can you learn using only death as a teacher? We don't know for sure, but some candidates are: soaring eagles, or pigeon navigation systems, or termite skyscrapers. It takes a while, but evolution is clever. Yet it is obviously blind and dumb. "I can't imagine any dumber type of learning than natural selection," says Ackley. 
In the space of all possible computation and learning, then, natural selection 
holds a special position. It occupies the extreme point where information transfer is minimized. It forms the lowest baseline of learning and smartness, below which learning doesn't happen and above which smarter, more complicated learning takes place. Even though we still do not fully understand the nature of natural selection in coevolutionary worlds, natural selection remains the elemental melting point of learning. If we could measure degrees of evolution (we can't yet) we would have a starting benchmark against which to rate other types of learning.Natural selection plays itself out in many guises. Ackley was right; computer 
scientists now realize that many modes of computation exist-many of them evolutionary. For all anyone knows, there may be hundreds of styles of evolution and learning. All such strategies, however, perform a search routine through a library or space. "Discovering the notion of the 'search' was the one and only brilliant idea that traditional AI research ever had," claims Ackley. A search can be accomplished in many ways. Natural selection-as it is run in organic life-is but one flavor.
Biological life is wedded to a particular hardware: carbon-based DNA 
molecules. This hardware limits the versions of search-by-natural-selection that can successfully operate upon it. With the new hardware of computers, particularly parallel computers, a host of other adaptive systems can be conjured up, and entirely different search strategies set out to shape them. For instance, a chromosome of biological DNA cannot broadcast its code to DNA molecules in other organisms in order for them to receive the message and alter their code. But in a computer environment you can do that.
David Ackley and Michael Littman, both of Bellcore's Cognitive Science 
Research Group, set out to fabricate a non-Darwinian evolutionary system in a computer. They chose a most logical alternative: Lamarckian evolution-the inheritance of acquired traits. Lamarckism is very appealing. Intuitively such a system would seem deeply advantageous over the Darwinian version, because presumably useful mutations would be adopted into the gene line more quickly. But a look at its severe computational requirements quickly convinces the hopeful engineer how unlikely such a system would be in real life. 
If a blacksmith acquires bulging biceps, how does his body reverse- engineer 
the exact changes in his genes needed to produce this improvement? The drawback for a Lamarckian system is its need to trace a particular advantageous change in the body back through embryonic development into the genetic blueprints. Since any change in an organism's form may be caused by more than one gene, or by many instructions interacting during the body's convoluted development, unraveling the tangled web of causes of any outward form requires a tracking system almost as complex as the body itself. Biological Lamarckian evolution is hampered by a strict mathematical law: that it is supremely easy to multiply prime factors together, but supremely hard to derive the prime factors out of the result. The best encryption schemes work on this same asymmetrical difficulty. Biological Lamarckism probably hasn't happened because it requires an improbable biological decryption scheme.
But computational entities don't require bodies. In computer evolution (as in 
Tom Ray's electric-powered evolution machine) the computer code doubles as both gene and body. Thus, the dilemma of deriving a genotype from the phenotype is moot. (The restriction of monolithic representation is not all that artificial. Life on Earth must have passed through this stage, and perhaps any spontaneously organizing vivisystem must begin with a 
genotype that is restricted to its phenotype, as simple self-replicating molecules would be.)
In artificial computer worlds, Lamarckian evolution works. Ackley and 
Littman implemented a Lamarckian system on a parallel computer with 16,000 processors. Each processor held a subpopulation of 64 individuals, for a grand total of approximately one million individuals. To simulate the dual information lines of body and gene, the system made a copy of the gene for each individual and called the copy the "body." Each body was a slightly different bit of code trying to solve the same problem as its million siblings. 
The Bellcore scientists set up two runs. In the Darwinian run, the body code 
would mutate over time. By chance a lucky guy might become code that provides a better solution, so the system chooses it to mate and replicate. But in Darwinism when it mates, it must use its original "gene" copy of the code-the code it inherited, not the improved body code it acquired during its lifetime. This is the biological way; when the blacksmith mates, he uses the code for the body he inherited, not the body he acquired.
In the Lamarckian run, by contrast, when the lucky guy with the improved 
body code is chosen to mate, it can use the improved code acquired during its lifetime as the basis for its mating. It is as if a blacksmith could pass on his massive arms to his offspring.
Comparing the two systems, Ackley and Littman found that, at least for the 
complicated problems they looked at, the Lamarckian system discovered solutions almost twice as good as the Darwinian method. The smartest Lamarckian individual was far smarter than the smartest Darwinian one. The thing about Lamarckian evolution, says Ackley, is that it "very quickly squeezes out the idiots" in a population. Ackley once bellowed to a roomful of scientists, "Lamarck just blows the doors off of Darwin!" 
In a mathematical sense, Lamarckian evolution injects a bit of learning into 
the soup. Learning is defined as adaptation within an individual's lifetime. In classical Darwinian evolution, individual learning doesn't count for much. But Lamarckian evolution permits information acquired during a lifetime (including how to build muscles or solve equations) to be incorporated into the long-term, dumb learning that takes place over evolution. Lamarckian evolution produces smarter answers because it is a smarter type of search.
The superiority of Lamarckism surprised Ackley because he felt that nature 
did things so well: "From a computer science viewpoint it seems really stupid that nature is Darwinian and not Lamarckian. But nature is stuck on chemicals. We're not." It got him thinking about other types of evolution and search methods that might be more useful if you weren't restricted to operating on molecules.continue... 
  
 
Out of Control
A group of researchers in Milan, Italy, have come up with a few new 
varieties of evolution and learning. Their methods fill a few holes in Ackley's 
proposed "space of all possible types of computation." Because they were inspired by the collective behavior of ant colonies, the Milan group call their searches "Ant Algorithms."
Ants have distributed parallel systems all figured out. Ants are the history of 
social organization and the future of computers. A colony may contain a million workers and hundreds of queens, and the entire mass of them can build a city while only dimly aware of one another. Ants can swarm over a field and find the choicest food in it as if the swarm were a large compound eye. They weave vegetation together in coordinated parallel rows, and collectively keep their nest at a steady temperature, although not a single ant has ever lived who knows how to regulate temperature.
An army of ants too dumb to measure and too blind to see far can rapidly 
find the shortest route across a very rugged landscape. This calculation perfectly mirrors the evolutionary search: dumb, blind, simultaneous agents trying to optimize a path on a computationally rugged landscape. Ants are a parallel processing machine.
Real ants communicate with each other by a chemical system called 
pheromones. Ants apply pheromones on each other and on their environment. These aromatic smells dissipate over time. The odors can also be relayed by a chain of ants picking up a scent and remanufacturing it to pass on to others. Pheromones can be thought of as information broadcasted or communicated within the ant system.
The Milan group (Alberto Colorni, Marco Dorigo, and Vittorio Maniezzo) 
constructed formulas modeled on ant logic. Their virtual ants ("vants") were dumb processors in a giant community operating in parallel. Each vant had a meager memory, and could communicate locally. Yet the rewards of doing well were shared by others in a kind of distributed computation.
The Italians tested their ant machine on a standard benchmark, the 
traveling salesman problem. The riddle was: what is the shortest route between a large number of cities, if you can only visit each city once? Each virtual ant in the colony would set out rambling from city to city leaving a trail of pheromones. The shorter the path between cities, the less the 
pheromone evaporated. The stronger the pheromone signal, the more other ants followed that route. Shorter paths were thus self-reinforcing. Run for 5,000 rounds or so, the ant group-mind would evolve a fairly optimal global route.
The Milan group played with variations. Did it make any difference if the 
vants all started at one city or were uniformly distributed? (Distributed was better.) Did it make any difference how many vants one ran concurrently? (More was better until you hit the ratio of one ant for every city, when the advantage peaked.) By varying parameters, the group came up with a number of computational ant searches.
Ant algorithms are a type of Lamarckian search. When one ant stumbles 
upon a short route, that information is indirectly broadcast to the other vants by the trail's pheromone strength. In this way learning in one ant's lifetime is indirectly incorporated into the whole colony's inheritance of information. Individual ants effectively broadcast what they have learned into their hive. Broadcasting, like cultural teaching, is a part of Lamarckian search. Ackley: "There are ways to exchange information other than sex. Like the evening news."
The cleverness of the ants, both real and virtual, is that the amount of 
information invested into "broadcasting" is very small, done very locally, and is very weak. The notion of introducing weak broadcasting into evolution is quite appealing. If there is any Lamarckism in earthly biology it is buried deep. But there remains a universe full of strange types of potential computation that might employ various modes of Lamarckian broadcasting. I know of programmers fooling around with algorithms to mimic "memetic" evolution-the flow of ideas (memes) from one mind to another, trying to capture the essence and power of cultural evolution. Out of all the possible ways to connect the nodes in distributed computers, only a very few, such as the ant algorithms, have even been examined.
As late as 1990, parallel computers were derided by experts as controversial, specialized, and belonging the lunatic fringe. They were untidy and hard to program. The lunatic fringe disagreed. In 1989, Danny Hillis boldly made a widely publicized bet with a leading computer expert that as early as 1995, more bits per month would be processed by parallel machines than by serial machines. He is looking right. As serial computers audibly groaned under the burden of pushing complex jobs through the tiny funnel of von Neumann's serial processor, a change in expert opinion suddenly swept through the computer industry. Peter Denning signaled the new perspective when he wrote in a paper published by Science ("Highly Parallel Computation," November 30, 1990), "Highly parallel computing architectures are the only means to achieve the computational rates demanded by advanced scientific problems." John Koza of Stanford's Computer Science Department says flatly, "Parallel computers are the future of computing. Period." 
But parallel computers remain hard to manage. Parallel software is a tangled 
web of horizontal, simultaneous causes. You can't check such nonlinearity for flaws since it's all hidden corners. There is no narrative to step through. The code has the integrity of a water balloon, yielding in one spot as another bulges. Parallel computers can easily be built but can't be easily programmed.
Parallel computers embody the challenge of all distributed swarm systems, 
including phone networks, military systems, the planetary 24-hour financial web, and large computer networks. Their complexity is taxing our ability to steer them. "The complexity of programming a massively parallel machine is probably beyond us," Tom Ray told me. "I don't think we'll ever be able to write software that fully uses the capacity of parallelism."
Little dumb creatures in parallel that can "write" better software than 
humans can suggests to Ray a solution for our desire for parallel software. "Look," he says, "ecological interactions are just parallel optimization techniques. A multicellular organism essentially runs massively parallel code of an astronomical scale. Evolution can 'think' of parallel programming ways that would take us forever to think of. If we can evolve software, we'll be way ahead." When it comes to distributed network kinds of things, Rays says, "Evolution is the natural way to program."
The natural way to program! That's an ego-deflating lesson. Humans should 
stick to what they do best: small, elegant, minimal systems that are fast and deep. Let natural evolution (artificially injected) do the messy big work.

Danny Hillis has come to the same conclusion. He is serious when he 
says he wants his Connection Machine to evolve commercial software. "We 
want these systems to solve a problem we don't know how to solve, but merely know how to state." One such problem is creating multimillion-line programs to fly airplanes. Hillis proposes setting up a swarm system which would try to evolve better software to steer a plane, while tiny parasitic programs would try to crash it. As his experiments have shown, parasites encourage a faster convergence to an error-free, robust software navigation program. Hillis: "Rather than spending uncountable hours designing code, doing error-checking, and so on, we'd like to spend more time making better parasites!" 
Even when technicians do succeed in engineering an immense program such 
as navigation software, testing it thoroughly is becoming impossible. But things grown, not made, are different. "This kind of software would be built in an environment full of thousands of full-time adversaries who specialize in finding out what's wrong with it," Hillis says, thinking of his parasites. "Whatever survives them has been tested ruthlessly." In addition to its ability to create things that we can't make, evolution adds this: it can also make them more flawless than we can. "I would rather fly on a plane running software evolved by a program like this, than fly on a plane running software I wrote myself," says Hillis, programmer extraordinaire. 
The call-routing program of long-distance phone companies tallies up to 
about 2 million lines of code. Three faulty lines in those 2 million caused the rash of national telephone system outages in the summer of 1990. And 2 million lines is no longer large. The combat computers aboard the Navy's Seawolf submarine contain 3.6 million lines of code. "NT," the new workstation computer operating system released by Microsoft in 1993, required 4 million lines of code. One-hundred-million-line programs are not far away.
When computer programs swell to billions of lines of code, just keeping 
them up and "alive" will become a major chore. Too much of the economy and too many people's lives will depend on billion-line programs to let them go down for even an instant. David Ackley thinks that reliability and up-time will become the primary chore of the software itself. "I claim that for a really complex program sheer survival is going to consume more of its resources." Right now only a small portion of a large program is dedicated to 
maintenance, error correction, and hygiene. "In the future," predicts Ackley, "99 percent of raw computer cycles are going to be spent on the beast watching itself to keep it going. Only that remaining 1 percent is going to be used for user tasks-telephone switching or whatever. Because the beast can't do the user tasks unless it survives."
As software gets bigger, survival becomes critical yet increasingly difficult. 
Survival in the everyday world of daily use means flexibility and evolvability. And it demands more work to pull off. A program survives only if it constantly analyzes its status, adjusts its code to new demands, cleanses itself, ceaselessly dissects anomalous circumstances, and always adapts and evolves. Computation must seethe and behave as if it is alive. Ackley calls it "software biology" or "living computation." Engineers, even on 24-hour beepers, can't keep billion-line code alive. Artificial evolution may be the only way to keep software on its toes, looking lively.
Artificial evolution is the end of engineering's hegemony. Evolution will take 
us beyond our ability to plan. Evolution will craft things we can't. Evolution will make them more flawless than we can. And evolution will maintain them as we can't.
But the price of evolution is the title of this book. Tom Ray explains: "Part of 
the problem in an evolving system is that we give up some control." 
Nobody will understand the evolved aviation software that will fly Danny 
Hillis. It will be an indecipherable spaghetti of 5 million strands of nonsense-of which perhaps only 2 million are really needed. But it will work flawlessly. 
No human will be able to troubleshoot the living software running Ackley's 
evolved telephone system. The lines of program are buried in an uncharted web of small machines, in an incomprehensible pattern. But, when it falters, it will heal itself. 
No one will control the destination of Tom Ray's soup of critters. They are 
brilliant in devising tricks, but there is no telling them what trick to work on next. Only evolution can handle the complexities we are creating, but evolution escapes our total command.
At Xerox PARC, Ralph Merkle is engineering very small molecules that can 
replicate. Because these replicators dwell in the microscopic scale of nanometers (smaller than bacteria) their construction techniques are called nanotechnology. At some point in the very near future the engineering skills of nanotechnology and the engineering skills of biotechnology converge; they are both treating molecules as machines. Think of nanotechnology as bioengineering for dry life. Nanotechnology has the same potential for artificial evolution as biological molecules. Merkle told me, "I don't want nanotechnology to evolve. I want to keep it in a vat, constrained by international law. The most dangerous thing that could happen to 
nanotechnology is sex. Yes, I think there should be international regulations against sex for nanotechnology. As soon as you have sex, you have evolution, and as soon as you have evolution, you have trouble."
The trouble of evolution is not entirely out of our control; surrendering some 
control is simply a tradeoff we make when we employ it. The things we are proud of in engineering-precision, predictability, exactness, and correctness-are diluted when evolution is introduced.
These have to be diluted because survivability in a world of accidents, 
unforeseen circumstances, shifting environments-in short, the real world-demands a fuzzier, looser, more adaptable, less precise stance. Life is not controlled. Vivisystems are not predictable. Living creatures are not exact. "'Correct' will go by the board," Ackley says of complex programs. "'Correct' is a property of small systems. In the presence of great change, 'correct' will be replaced by 'survivability'."
When the phone system is run by adaptable, evolved software, there will be 
no correct way to run it. Ackley continues: "To say that a system is 'correct' in the future will sound like bureaucratic double-talk. What people are going to judge a system on is the ingenuity of its response, and how well it can respond to the unexpected." We will trade correctness for flexibility and durability. We will trade a clean corpse for messy life. Ackley: "It will be to your advantage to have an out-of-control, but responsive, monster spend 1 percent of itself on your problem, than to have a dedicated little correct ant of a program that hasn't got a clue about what in the world is going on."
A student at one of Stuart Kauffman's lectures once asked him, "How do you 
evolve for things you don't want? I see how you can get a system to evolve what you want; but how can you be sure it won't create what you don't want?" Good question, kid. We can define what we want narrowly enough to breed for it. But we often don't even know what we don't want. Or if we do, the list of things that are unacceptable is so long as to be impractical. How can we select out disadvantageous side effects?
"You can't." Kauffman replied bluntly.
That's the evolutionary deal. We trade power for control. For control junkies 
like us, this is a devil's bargain. 
Give up control, and we'll artificially evolve new worlds and undreamed-of 
richness. Let go, and it will blossom.
Have we ever resisted temptation before?
continue...   
 
Out of Control