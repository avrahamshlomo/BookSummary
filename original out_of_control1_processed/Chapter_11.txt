NETWORK ECONOMICS 
John Perry Barlow's exact mission in life is hard to pin down. He owns a 
ranch in Pinedale, Wyoming. He once made a bid for a Republican seat in 
that state's Senate. He often introduces himself to boomer types as the B-string lyricist for that perennial underground cult band, the Grateful Dead. It's a role he relishes, particularly for the cognitive dissonance it serves up: A Republican Deadhead? 
At any one moment Barlow may be working on getting a whaleboat launched in Sri Lanka (so environmentalists can monitor gray whale migrations), or delivering an address to an electrical engineers association on the future of privacy and freedom of speech. He is as likely to be sitting in a Japanese hot spring in Hokkaido with Japanese industrialists, brainstorming on ways to unify the Pacific Rim, as he would be soaking in a sweat lodge with the last of the space visionaries planning to settle Mars. I know Barlow from an experimental computer meeting place, the WELL, a place where no one has a body. There, he plays the role of "hippie mystic."
On the WELL, Barlow and I met and worked together years before we ever 
met in the flesh. This is the usual way of friendships in the information age. Barlow has about ten phone numbers, several different towns where he parks his cellular phone, and more than one electronic address. I never know where he is, but I can almost always reach him in a couple of minutes. The guy flies on planes with a laptop computer plugged into a in-flight phone. The numbers I hit to contact him might take me anywhere in the world.
I get discombobulated by this disembodiment. When I connect, I am 
confused if I can't picture at least what part of the globe I'm connected to. He might not mind being placeless, but I mind. When I dial what I think is him in New York City and I wind up with him over the Pacific, I feel flung.
"Barlow, where are you right now?" I demand impatiently during an intense 
phone call discussing some pretty hairy, nontrivial negotiations.
"Well, when you first called I was in a parking lot. Now I'm in a luggage 
store getting my luggage repaired.""Gee," I said, "why don't you just get a receiver surgically wired into your 
brain? It'd be a lot more convenient. Free up your hands."
"That's the idea," he replies in total seriousness.
Barlow moved from the emptiness of Wyoming and is now homesteading in 
the vaster wilds of cyberspace, the frontier where our previous conversation technically took place. As originally envisioned by writer William Gibson, cyberspace encompasses the realm of large electronic networks which are invisibly spreading "underneath" the industrial world in a kind of virtual sprawl. In the near future, according to Gibson's science-fiction, cyberspace explorers would "jack in" to a borderless maze of electronic data banks and video-gamelike worlds. A cyberspace scout sits in a dark room and then plugs a modem directly into his brain. Thus jacked in, he cerebrally navigates the invisible world of abstracted information, as if he were racing through an infinite library. By all accounts, this version of cyberspace is already appearing in patches.
Cyberspace, as expanded by hippie mystic Barlow, is something yet broader. 
It includes not only the invisible matrix of databases and networks, and not only the three-dimensional games one can enter wearing computer-screen goggles, but also the entire realm of any disembodied presence and of all information in digital form. Cyberspace, says Barlow, is the place that you and a friend "are" when you are both talking on the phone.
"Nothing could be more disembodied than cyberspace. It's like having your 
everything amputated," Barlow once told a reporter. Cyberspace is the mall of network culture. It's that territory where the counterintuitive logic of distributed networks meets the odd behavior of human society. And it is expanding rapidly. Because of network economics, cyberspace is a resource that increases the more it is used. Barlow quips that it is "a peculiar kind of real estate which expands with development."

I bought my first computer to crunch a database of names for a mail order 
company I owned. But within several months of getting my first Apple II 
running, I hooked the machine up to a telephone and had a religious experience. 
On the other side of the phone jack, an embryonic web stirred-the young 
Net. In that dawn I saw that the future of computers was not numbers but connections. Far more voltage crackled out of a million interconnected Apple IIs than within the most coddled million-dollar supercomputer standing alone. Roaming the Net I got a hit of network juice, and my head buzzed. 
Computers, used as calculating machines, would, just as we all expected, 
whip up the next efficient edition of the world. But no one expected that once used as communication machines, networked computers would overturn the improved world onto an entirely different logic-the logic of the Net. 
In the Me-Decades, the liberation of personal computers was just right. 
Personal computers were personal slaves. Loyal, bonded silicon brains, hired for cheap and at your command, even if you were only 13. It was plain as daylight that personal computers and their eventual high-powered offspring would reconfigure the world to our specifications: personal newspapers, video on demand, customized widgets. The focus was on you the individual. But in one of those quirks reality is famous for, the real power of the silicon chip lay not in its amazing ability to flip digits to think for us, but in its uncanny ability to use flipped switches to connect us. We shouldn't call them computers; we really should call them connectors.
By 1992 the fastest-growing segment of the computer industry was network 
technology. This reflects the light-speed rate at which every sector of business is electronically netting itself into a new shape. By 1993, both Time and Newsweek featured cover stories on the fast-approaching data superhighway that would connect television, telephones, and the Sixpack family. In a few years-no dream-you would pick up a gadget and get a "video dialtone" which would enable you to send or receive a movie, a color photograph, an entire database, an album of music, some detailed blueprints, or a set of books-instantly-to or from anyone, anywhere, anytime. Networking at that scale would truly revolutionize almost every business. It 
would alter:
●     What we make 
●     How we make it 
●     How we decide what to make 
●     The nature of the economy we make it in. 
There is hardly a single aspect of business not overhauled, either directly or indirectly, by the introduction of networking logic. Networks-not merely computers alone-enable companies to manufacture new kinds of innovative products, in faster and more flexible ways, in greater response to customers' needs, and all within a rapidly shifting environment where competitors can do the same. In response to these groundswell changes, laws and financing change, too, not to mention the incredible alterations in the economy due to global 24-hour networking of financial institutions. And not to mention the feverish cultural brew that will burst as "the Street" takes hold of this web and subverts it to its own uses.
Network logic has already shaped the products that are shaping business 
now. Instant cash, the product which is disgorged from ATM machines, could only be born in a network. Ditto for credit cards of any stripe. Fax machines, too. But also such things as the ubiquitous color printing in our lives. The high quality and low cost of modern four-color printing is made possible by a networked printing press which coordinates the hi-speed overlap of each color as it zips through the web of rollers. Biotech pharmaceuticals require networked intelligence to manage living soups as they flow by the barrelful from one vat to the next. Even processed snack foods are here to tempt us because the dispersed machines needed to cook them can be coordinated by a network. 
Ordinary manufacturing becomes better when managed by netted 
intelligence. Networked equipment creates not only purer steel and glass, but its adaptive nature allows more varieties to be made with the same equipment. Small differences in composition can be maintained during manufacturing, in effect creating new kinds of precise materials where once there was only one fuzzy, imprecise material.
Networking will also inform the maintenance of products. Already, in 1993, 
some business equipment (Pitney Bowes's fax machines, Hewlett-Packard's minicomputers, General Electric's body scanners) can be diagnosed and repaired from a distance. By plugging a phone line into a machine, operators at the factory can peek inside its guts to see if it is working properly and often fix it if not. The technique of remote diagnostics was developed by satellite makers who had no choice but to do repairs at a distance. Now the 
methods are being used to fix a fax machine, to dissect a hard disk, or to speed repair of an X-ray machine thousands of miles away. Sometimes new software can be uploaded into the machine to create a fix; at the very least, the repairman can learn beforehand what parts and tools he'll need if he visits and thus speed up the on-site repair. In essence, these networked devices become nodes of a larger distributed machine. In time all machines will be wired into a net so that they warn repairmen when they are flaking out, and so that they can receive updated intelligence and thus improve while on the job. 
The Japanese perfected the technique of combining well-educated human 
beings and networked computer intelligence into one seamless companywide network to ensure uncompromised quality. Intense coordination of critical information in Japanese manufacturing corporations gave the world palm-size camcorders and durable cars. While the rest of the industrialized sector frantically installs network-driven manufacturing machinery, the Japanese have moved on to the next frontier in network logic: flexible manufacturing and mass customization. For instance the National Bicycle Industrial Company in Kokubu, Japan, builds custom bicycles on an assembly line. You can order any one of 11 million variations of its models to suit your taste, at prices only 10 percent higher than mass-produced noncustomized models.
The challenge is simply stated: Extend the company's internal network 
outward to include all those with whom the company interacts in the marketplace. Spin a grand web to include employees, suppliers, regulators, and customers; they all become part of your company's collective being. They are the company. 
Cases in both Japan and America where corporations have started building 
an extended distributed company demonstrate the immense power it releases. For example, Levi Strauss, makers of jeans for the whole world, has networked a large portion of its being. Continuous data flows from it headquarters, its 39 production plants, and its thousands of retailers into a economic superorganism. As stone-washed jeans are bought at the mall in, say, Buffalo, a message announcing those sales flies that night from the mall's cash register into Levi's net. The net consolidates the transaction with transactions from 3,500 other retail stores and within hours triggers the order for more stone-washed jeans from a factory in Belgium, or more dye from Germany, or more denim cloth from the cotton mills in North Carolina. 
The same signal spurs the networked factory into action. Here bundles of 
cloth arrive from the mills decked in bar codes. As the stacks of cloth become pants, their bar-coded identity will be followed with hand-held laser readers, from fabric to trucker to store shelf. A reply is sent back to the mall store saying the restocking pants are on their way. And they will be, in a matter of days. 
So tight is this loop of customer purchase/order materials/make, that other highly networked clothiers such as Benetton boast that they don't dye their 
sweaters until they are on their way out the door. When customers at the local chains start ringing up turquoise jumpers, in a few days Benetton's network will begin dyeing more jumpsuits in that color. Thus, the cash registers, not fashion mavens, choose the hues of the season. In this way, hip Benetton stays abreast of the unpredictable storms of fashion. 
If you link computer-assisted design tools, and computer-assisted 
manufacturing, then not only can colors be nimbly manipulated but entire designs as well. A new outfit is quickly drawn up, made in low volume, distributed to stores, and then rapidly modified or multiplied if successful. The whole cycle is measured in days. Up until recently, the cycle of a far more limited choice was measured in seasons and years. Kao, a detergent and toiletry manufacturer in Japan, has developed a distribution system so tightly networked that it delivers even the smallest order within 24 hours.
Why not make cars or plastics this way? In fact, you can. A truly adaptable 
factory must be modular. Its tools and workflow can be quickly modified and reassembled to manufacture a different version of car or a different formula plastic. One day the assembly line is grinding out station wagons or Styrofoam, the next day jeeps or Plexiglas. Technicians call it flexible manufacturing. The assembly line adapts to fit the products needed. It's a hot field of research with immense potential. If you can alter the manufacturing process on the fly without stopping the flow, you then have the means to make stuff in batches of one. 
But this flexibility demands tiptoe agility from multi-ton machines that are 
presently bolted to the floor. To get them to dance requires substituting a lot of mass with a lot of networked intelligence. Flexibility has to sink deep into the system to make flexible manufacturing work. The machine tools must themselves be adjustable, the schedules of material delivery must turn on a dime, the labor force must coordinate as a unit, the suppliers of packaging must be fluid, the trucking lines must be adaptable, the marketing must be in sync. That's all done with networks. 
Today my factory needs 21 flatbed trucks, 73 tons of acetate resin, 2,000 
kilowatts, and 576 man hours. The next day I may not need any of those. So if you are the acetate or electric company, you'll need to be as nimble as I am if we are to work together. We'll coordinate as a network, sharing information and control, decentralizing functions between us. It will be hard at times to tell who is working for whom. 
Federal Express used to deliver key parts for IBM computers. Now they 
warehouse them too. By means of networks, Federal Express locates the just-finished part recently arrived in a FedEx warehouse from some remote overseas IBM supplier. When you order an item from an IBM catalog, FedEx brings it to you via their worldwide delivery service. An IBM employee may never touch the piece. So when the Federal Express man delivers the part to your door, who sent it, IBM or Federal Express? Schneider National, the first national trucking company to have all its trucks fully networked in real time 
by satellite, has some major customers who deposit their orders directly into Schneider's dispatching computers and who are billed by the same method. Who is in charge? Where does the company end and the supplier start?
Customers are being roped into the distributed company just as fast. 
Ubiquitous 800-numbers just about ring on the factory floor, as the feedback of users shape how and what the assembly line makes.

One can imagine the future shape of companies by stretching them until 
they are pure network. A company that was pure network would have the 
following traits: distributed, decentralized, collaborative, and adaptive.
Distributed-There is no single location for the business. It dwells among 
many places concurrently. The company might not even be headquartered in one place. Apple Computer, Inc., has numerous buildings spread thickly over two towns. Each one is a "headquarter" for a different function of the company. Even small businesses may be distributed within the same locality. Once networked, it hardly matters whether you are on the floor below, or across town. 
Open Vision, based in Pleasanton, California, is an example of a rather 
ordinary, small software company, molded in the new pattern. "We are operating as a true distributed company," said CEO Michael Fields. Open Vision has clients and employees in most US cities, all served on computer networks, but "most of them don't even know where Pleasanton is," Fields told the San Francisco Chronicle.
Yet in this stretch toward ultimate networks, companies will not break down 
into a network of individuals working alone. The data collected so far, as well as my own experience, says that the natural resolution of a purely distributed company coalesces into teams of 8 to 12 people working in a space together. A very large global company in the pure network form could be viewed as a system of cells of a dozen people each, including minifactories manned by a dozen people, a "headquarters" staffed with a dozen, profit centers managed by eight and suppliers run by ten people.
Decentralized-How can any large-scale project ever get anything done with 
only ten people? For most of the industrial revolution, serious wealth was made by bringing processes under central control. Bigger was more efficient. The "robber barons" of yesteryear figured out that by controlling every vital and auxiliary aspect of their industry, they could make millions. Steel companies proceeded to control the ore deposits, mine their own coal, set up their own railways, make their own equipment, house their own workers, and strive for self-containment within the borders of a gigantic company. That worked magnificently when things moved slowly. Now, when the economy shifts daily, owning the whole chain of production is 
a liability. It is efficient only while the last hours of its relevancy lasts. Once that moment of power recedes, control has to be traded in for speed and nimbleness. Peripheral functions, like supplying your own energy, are quickly passed on to another company. 
Even supposedly essential functions are subcontracted out. For instance, 
Gallo Winery no longer grows the specialized grapes required for its wines; it farms that chore out to others and focuses on brewing and marketing. A car rental company subcontracts out the repair and maintenance of its fleet, and focuses on renting. One passenger airline subcontracted its cargo space on transcontinental flights (a vitally important profit center) to an independent freight company, figuring they would manage it better and earn the airline more than it could itself. 
Detroit automobile manufacturers were once famous for doing everything 
themselves. Now they subcontract out about half of their functions, including the rather important job of building engines. General Motors even hired PPG Industries to handle the painting of auto bodies-a critical job in terms of sales-within GM's factories. In the business magazines this pervasive decentralization by means of subcontracting is called "outsourcing."
The coordination costs for large-scale outsourcing have been reduced to 
bearable amounts by electronic trading of massive amounts of technical and accounting information. In short, networks make outsourcing feasible, profitable, and competitive. The jobs one company passes off to another can 
be passed back several times until they rest upon the shoulders of a small, 
tightly knit group, who will complete the job with care and efficiency. That group will most likely be a separate company, or they may be an autonomous subsidiary. 
Research shows that the transactional costs needed to maintain the quality 
of a task as it stretches across several companies are higher than if the job stayed within one company. However: (1) those costs are being lowered every day with network technology such as electronic data transfers (EDI) and video-conferencing, and (2) those costs are already lower in terms of 
the immense gains in adaptability-not having to manage jobs you no longer 
need, and being able to start jobs you will need-that centralized companies lack.
Extending outsourcing to its logical conclusion, a 100 percent networked 
company would consist solely of one office of professionals linked by network technology to other independent groups. Many invisible million-dollar businesses are being run from one office with two assistants. And some don't have an office at all. The large advertising firm of Chiat/Day is working on dismantling its physical headquarters. Project team members will rent hotel conference rooms for the duration of the project, working on 
portable computers and call-forwarding. They'll disband and regroup when the project is done. Some of those groups might be "owned" by the office; others would be separately controlled and financed. 
Let's imagine the office of the future in a hypothetical Silicon Valley 
automobile manufacturer that I'll call Upstart Car, Inc. Upstart Car intends to compete with the big three Japanese automobile giants.
Here's Upstart's blueprint: A dozen people share a room in a sleek office 
building in Palo Alto, California. Some finance people, four engineers, a CEO, a coordinator, a lawyer, and a marketing guy. Across town in a former warehouse, crews assemble 120-mpg, nonpolluting cars made from polychain composite materials, ceramic engines, and electronic everything else. The hi-tech plastics come from a young company with whom Upstart has formed a joint venture. The engines are purchased in Singapore; other automobile parts arrive each day in bar-coded profusion from Mexico, Utah, and Detroit. The shipping companies deal with temporary storage of parts; only what is needed that day appears at the plant. Cars, each one customer-tailored, are ordered by a network of customers and shipped the minute they are done. Molds for the car's body are rapidly shaped by computer-guided lasers, and fed designs generated by customer response and targeted marketing. A flexible line of robots assemble the cars. 
Robot repair and improvement is outsourced to a robot company. Acme 
Plant Maintenance Service keeps the factory sheds going. Phone reception is hired out to small outfit physically located in San Mateo. The clerical work is handled by a national agency who services all the other groups in the company. Same with computer hardware. The marketing and legal guys each oversee (of course) the marketing and legal services which Upstart also hires out. Bookkeeping is pretty much entirely computerized, but an outside accounting firm, operating from remote terminals, tends to any accounting requests. In total about 100 workers are paid directly by Upstart, and they are organized into small groups with varying benefit plans and pay schedules. As Upstart's cars soar in popularity, it grows by helping its suppliers grow, negotiating alliances, and sometimes investing in their growth.
Pretty far out, huh? It's not so farfetched. Here's how a real pioneering 
Silicon Valley company was launched a decade ago. James Brian Quinn writes in the March-April 1990 Harvard Business Review : 
Apple bought microprocessors from Synertek, other chips from Hitachi, 
Texas Instruments, and Motorola, video monitors from Hitachi, power supplies from Astec, and printers from Tokyo Electric and Qume. Similarly, Apple kept its internal service activities and investments to a minimum by outsourcing application software development to Microsoft, promotion to Regis McKenna, product styling to Frogdesign, and distribution to ITT and ComputerLand.Businesses aren't the only ones to tap the networked benefits of 
outsourcing. Municipalities and government agencies are rapidly following suit. As one example out of many, the city of Chicago hired EDS, the computer outsourcing company Ross Perot founded, to handle its public parking enforcement. EDS devised a system based on hand-held computers that print out tickets and link into a database of Chicago's 25,000 parking meters to increase fine collection. After EDS outsourced this service for the city, parking tickets that were paid off jumped from 10 percent to 47 percent, raising $60 million in badly needed income.
Collaborative-Networking internal jobs can make so much economic sense 
that sometimes vital functions are outsourced to competitors, to mutual benefit. Enterprises may be collaborators on one undertaking and competitors on another, at the same time. 
Many major domestic airlines in the U.S. outsource their complex 
reservation and ticketing procedures to their competitor American Airlines. Both MasterCard and Visa credit card companies sometimes delegate their vital work of processing customer charges and transactions to arch-competitor American Express. "Strategic Alliances" is the buzz word for corporations in the 1990s. Everyone is looking for symbiotic partners, or even symbiotic competitors.
The borders between industries, between transportation, wholesaling, 
retailing, communications, marketing, public relations, manufacturing, warehousing all disappear into an indefinite web. Airlines run tours, sell junk by direct mail, arrange hotel reservations, while computer companies hardly even handle computer hardware. 
It may get to the point that wholly autonomous companies become rare. The 
metaphor for corporations is shifting from the tightly coupled, tightly bounded organism to the loosely coupled, loosely bounded ecosystem. The metaphor of IBM as an organism needs overhauling. IBM is an ecosystem.
Adaptive-The shift from products to service is inevitable because automation 
keeps lowering the price of physical reproduction. The cost of copying a disk of software or a tape of music is a fraction of the cost of the product. And as things continue to get smaller, their cost of reproduction continues to shrink because less material is involved. The cost of manufacturing a capsule of drug is a fraction of the cost it sells for. 
But in pharmaceutical, computer, and gradually all hi-tech industries, the 
cost of research, development, stylizing, licenses, patents, copyrights, marketing and customer support-the service component-are increasingly substantial. All are information and knowledge intensive. 
Even a superior product is not enough to carry a company very long these days. Things churn so fast that innovative substitutions (wires built on light 
instead of electrons), reverse engineering, clones, third party add-ons that make a weak product boom, and quickly shifting standards (Sony lost badly on Beta VCRs but may yet prevail with 8-mm tapes) all conspire to bypass the usual routes to dominance. To make money in the new era, follow the flow of information.
A network is a factory for information. As the value of a product is increased 
by the amount of knowledge invested in it, the networks that engender the knowledge increase in value. A factory-made widget once followed a linear path from design to manufacturing and delivery. Now the biography of a flexibly processed widget becomes a net, distributed over many departments in many places simultaneously, and spilling out beyond the factory, so that it is difficult to say what happens first or where it happens. 
The whole net happens at once. Marketing, design, manufacturing, 
suppliers, buyers are all involved in the creation of the successful product. Designing a product concurrently entails having marketing, legal, and engineering teams all design the product at once, instead of sequentially as in the past. 
Retail products (cans of soda, socks) have communicated their movement at 
the cash register to the back office since the 1970s when the UPC bar code became popular in stores. However in a full-bore network economy, the idea is to have these items communicate to the front office and customer as well by adding weak communication abilities. Manufacturing small items with active microchips instead of passive bar codes embedded into them means you now have hundreds of items with snail-minds sitting on a shelf in a discount store by the thousands. Why not turn them on? They are now smart packages. They can display their own prices, thank you, easily adjusting to sales. They can recalculate their prices if the store owner wants to sell them at a premium or if you the shopper are carrying a coupon or discount card of some sort. And a product would remember if you passed it over even after seeing the sale price, much to the interest of the store owner and manufacturer. At least you looked, boasts the product's ad agency. When shelf items acquire awareness of each other and themselves and interact with their consumers, they rapidly erupt into a different economy.

Despite my sunny forecast for the network economy, there is much about 
it that is worrisome. These are the same concerns that accompany other 
large, decentralized, self-making systems:
●     You can't understand them. 
●     You have less control. 
●     They don't optimize well. 
As companies become disembodied into some Barlowian cyberspace, they take on the character of software. Clean, massless, quick, useful, mobile, and interesting. But also complicated and probably full of bugs no one can find.
If the companies and products of the future become more like software of 
today, what does that promise? Televisions that crash? Cars that freeze up suddenly? Toasters that bomb?
Large software programs are about the most complex things humans can 
make right now. Microsoft's new operating system had 4 million lines of code. Naturally Bill Gates claims there will be no bugs in it after the 70,000 beta-test sites are done checking it. 
Is it possible for us to manufacture extremely complex things without 
defects (or even with merely a few defects)? Will network economics help us to create complexity without any bugs, or just complexity with bugs?
Whether or not companies become more like software themselves, it is 
certain that more and more of what they make depends on more complex software, so the problems of creating complexity without defects becomes essential.
And in an age of simulations, the problem of verifying the truthfulness of a 
simulation is the same type of problem as testing massive complex software to determine whether it is or is not flawless. David Parnas, a Canadian computer scientist, developed a set of eight 
criticisms of President Reagan's "Star Wars" (SDI) initiative. He based his criterion on the inherent instabilities of extremely complex software, which is what SDI essentially was. The most interesting of Parnas's points was that there are two kinds of complex systems: continuous, and discontinuous.
When GM tests a new car on its track field, it puts the car through its paces 
at different speeds. It will test how it handles a sharp curve going at 50, 60, 70 mph. To no one's surprise, the car's performance varies continuously with the speed. If the car passed the curve test at 50, 60, and 70 mph, then the GM engineers know-without explicit testing-that it will also pass at all the intermediate speeds of 55 and 67 mph. 
They don't have to worry that at 55 mph the car will sprout wings or go into 
reverse. How it behaves at 55 will be some interpolated function of what it does at 50 and 60 mph. A car is a continuous system.
Computer software, distributed networks, and most vivisystems are 
discontinuous systems. In complex adaptive systems you simply can't rely on interpolated functions. You can have software that has been running reliably for years, then suddenly, at some particular set of values (63.25 mph), kaboom!, the system bombs, or something novel emerges. 
The discontinuity was always there. All the neighboring values had been 
tested but this particular exact set of circumstances had not. In retrospect it is obvious why the bug caused the system to crash and perhaps even why one should have looked for it. But in systems with astronomical numbers of possibilities, it is impossible to test every case. Worse, you can't rely on sampling because the system is discontinuous. 
A tester can have no confidence that unexamined values in extremely 
complex systems will perform continuously with examined values. Despite that hurdle there is a movement toward "zero-defect" software design. Naturally it's happening in Japan.
For small programs, zero is 0.000. For extremely large programs, zero is 
0.001, and falling. That's the number of defects per thousand lines of code (KLOC), and it is just one crude measure of quality. The methods for attaining zero-defect software borrow heavily from the Japanese engineer Shigeo Shingo's pioneering work on zero-defect manufacturing. Of course, computer scientists claim, "software is different." It duplicates perfectly in production, so the only problem is making the first copy. 
In network economics the major expense of new product development 
stems from designing the manufacturing process and not designing the product. The Japanese have excelled at designing and improving processes; Americans have excelled at designing and improving products. The Japanese view software as a process rather than product. And in the dawning network 
culture, more and more of what we make-certainly more and more of our wealth-is tangled up in symbol processing which resembles code more than corn.
Software reliability guru C. K. Cho admonished the industrialist not to think 
of software as a product but as a portable factory. You are selling-or giving-a factory (the program code) to others who will use it to manufacture an answer when they need one. Your problem is to make a factory that will generate zero-defect answers. The methods of making a factory that produces perfectly reliable widgets can be easily applied to creating a factory that makes perfectly reliable answers.
Ordinarily, software is constructed according to three centralized milestones. 
It is first designed as one big picture, then coded in detail, then finally, near the end of the project, it is tested as an interacting whole. Zero-defect quality design proceeds by thousands of distributed "inchstones," instead of a few milestones. Software is designed, coded, and tested daily, in a hundred cubicles, as each person works on it. 
The zero-defect evangelists have a slogan that summarizes network 
economics: "Every person within a company has a customer." Usually that customer is the coworker you hand your work off to. And you don't hand off your work until you've done the milestone cycle in miniature-specifying, coding, and testing what you made as if you were shipping it. 
When you ship your work to your customer/coworker, she immediately 
checks it and lets you know how you did, reporting errors back to you, which you correct. In essence, software is grown from the bottom up in a manner not unlike Rodney Brooks's subsumption architecture. Each inchstone is a small module of code that works for sure, and from which more complex layers are added and tested.
Inchstones alone won't get you zero-defect software. Underlying the zero 
goal is a key distinction. A defect is an error shipped. An error corrected before shipping in not a defect. Shingo says, "What we absolutely cannot prevent are errors, but we can keep those errors from generating defects." Therefore, the task of zero-defect design is to detect errors early and rectify them early. 
But that much is obvious. The real progress comes from identifying the 
cause of the error early and then eliminating the cause early. If a worker is inserting the wrong bolt, institute a system that prevents the incorrect bolt from being inserted. To err is human; to manage error is system.
The classic Japanese invention for error prevention is a "poka-yoke" system-
making things foolproof. On assembly lines, cleverly simple devices prevent mistakes. A holding tray may have a specific hole for every bolt so that if there are any bolts left the operator knows he missed one. An example of 
poka-yoke for software production is a spell-checker that doesn't allow the programmer to type a misspelled command or even to enter an illegal (illogical) command. Software developers have an ever widening choice of amazingly sophisticated "automatic program correction" packages that check ongoing programming to prevent typical errors. 
State-of-the-art developer tools perform meta-evaluations on a program's 
logic-"Hey, that step doesn't make sense!" it says-eliminating logical errors at the first chance. A software industry trade magazine recently listed almost a hundred error test and removal tools for sale. The most elegant of these programs offer the creator a legitimate alternative, just as a good spell-checker does, to correct the error.
Another poka-yoke of great importance is the modularization of complex 
software. A 1982 study published in the IEEE Transactions on Software Engineering revealed how the same number of lines of code broken up into smaller subprograms would decrease the number of faults, all other things being equal. A 10,000-line program in one hunk would exhibit 317 faults; when broken into three subprograms, 10,000 lines would total a lesser 265 faults. The decrease per subdivision follows a slight linear function, so fragmenting is not a cure-all, but it is a very reliable trick.
Furthermore, below a certain threshold, a subprogram can be small enough 
to be absolutely free of defects. IBM's code for their IMS series was written in modules of which three-quarters were entirely defect free. That is, 300 out of 425 modules had zero defects. Over half of the faults were found in only 31 of the modules. The move toward modular software, then, is a move in the direction of reliability. 
The hottest frontier right now in software design is the move to object-
oriented software. Object-oriented programming (OOP) is relatively decentralized and modular software. The pieces of an OOP retain an integrity as a standalone unit; they can be combined with other OOP pieces into a decomposable hierarchy of instructions. An "object" limits the damage a bug can make. Rather than blowing up the whole program, OOP effectively isolates the function into a manageable unit so that a broken object won't disrupt the whole program; it can be swapped for a new one just like an old brake pad on a car can be swapped for a better one. Vendors can buy and sell libraries of prefabricated "objects" which other software developers can buy and reassemble into large, powerful programs very quickly, instead of writing huge new programs line by line. When it comes time to update the massive OOP, all you have to do is add upgraded or new objects.
Objects in OOP are like Lego blocks, but they also carry a wee bit of 
intelligence with them. An object can be similar to a file folder icon on a Macintosh screen, but one that knows it's a folder and would respond to a program's query for all file folders to list their contents. An OOP object could also be a tax form, or an employee in a firm's database, or an e-mail message. Objects know what tasks they can and can't do, and they 
communicate laterally with each other.
Object-oriented programs create a mild distributed intelligence in software. 
Like other distributed beings, it is resilient to errors, it heals faster (remove the object), and it grows by incrementally assembling working subunits.
The 31 error-filled modules mentioned earlier that were found in IBM's code 
beautifully illustrate one characteristic of software that can be used to achieve sigma-precision quality. Errors tend to cluster. Zero Defect Software, the bible of the movement says, "The next error you find is far more likely to be found in the module where eleven other errors have already been found, rather than in the module where no errors have been found." Error clustering is so prevalent in software that it is known as the cockroach rule of thumb: where there is one error seen, another twenty-three lurk unnoticed. 
Here's the remedy, according to the Zero bible: "Do not spend money on 
defect-prone code, get rid of it. Coding cost is nearly irrelevant compared to the cost of repairing error-prone modules. If a software unit exceeds an error threshold, throw it out, and have a different developer do the recoding. Discard work in progress that shows a tendency toward errors because early errors predict late errors."
As software programs mushroom in complexity, it becomes impossible to 
exhaustively test them at the end. Because they are discontinuous systems, they will always harbor odd corners or a fatal response triggered by a one-in-a-million combination of input that eluded detection of both systematic and sample-based testing. And while statistical sampling can tell if there are likely to be faults left, it can't locate them. 
The neo-biological approach is to assemble software from working parts, 
while continuously testing and correcting the software as it grows. One still has the problems of unexpected "emergent behaviors" (bugs) arising from the aggregation of bugless parts. But there is hope that as long as you only need to test at the new emergent level (since the lower orders are already proven) you have a chance-and you are far ahead of where you'd be if you had to test for emergent bugs along with deeper sub-bugs.
Ted Kaehler invents new kinds of software languages for his living. He was 
an early pioneer of object-oriented languages, a codeveloper of SmallTalk and HyperCard. He's now working on a "direct manipulation" language for Apple Computers. When I asked him about zero-defect software at Apple he waved it off. "I think it is possible to make zero defects in production software, say if you are writing yet another database program. Anywhere you really understand what you are doing, you can do it without defects."
Ted would never get along in a Japanese software mill. He says, "A good programmer can take anything known, any regularity, and cleverly reduce it 
in size. In creative programming then, anything completely understood disappears. So you are left writing down what you don't know....So, yeah, you can make zero-defect software, but by writing a program that may be thousands of lines longer than it needs to be."
This is what nature does: it sacrifices elegance for reliability. The neural 
pathways in nature continue to stun scientists with how non-optimized they are. Researchers investigating the neurons in a crayfish's tail reported astonishment at how clunky and inelegant the circuit was. With a little work they could come up with a more parsimonious design. But the crayfish tail circuit, more redundant than it perhaps needed to be, was error free.
The price of zero-defect software is that it's over-engineered, overbuilt, a bit 
bloated, and never on the edge of the unknown where Ted and friends hang out. It trades efficiency of execution for efficiencies of production. 
I asked Nobel Laureate Herbert Simon how zero-defect philosophy squared 
with his concept of "satisficing"-don't aim for optimization, aim for good enough. He laughed and said, "Oh, you can make zero-defect products. The question is, can you do it profitably? If you are interested in profits, then you need to satisfice your zero defects." There's that complexity tradeoff again.
The future of network economics is in devising reliable processes, rather 
than reliable products. At the same time the nature of this economy means that processes become impossible to optimize. In a distributed, semiliving world, goals can only be satisficed, and then for only a moment. A day later the landscape has changed, and another upstart is shaping the playing field.

Characteristics of the Emerging Network Economy:
Executive Summary
As I see it, a few general systemic patterns will prevail in the economy of 
the near future. And what economic plan would be without its executive summary? Certainly not this one. Cataloged below are some traits I believe a networked-based economy would exhibit:
●     Distributed Cores-The boundaries of a company blur to obscurity. Tasks, even seemingly core tasks like accounting or manufacturing, are jobbed out via networks to contractors, who subcontract the tasks further. Companies, from one-person to Fortune 500, become societies of work centers distributed in ownership and geography.
●     Adaptive Technologies-If you are not in real time, you are dead. Bar codes, laser scanners, cellular phones, 700-numbers, and satellite uplinks which are directly connected to cash registers, polling devices, and delivery trucks steer the production of goods. Heads of lettuce, as well as airline tickets, have shifting prices displayed on an LED on the grocery shelf.
●     Flex Manufacturing-Smaller numbers of items can be produced in smaller time periods with smaller equipment. Film processing used to happen in a couple of national centers and take weeks. It's now done in a little machine on every street corner in a hour. Modular equipment, no standing inventory, and computer-aided design shrink product development cycles from years to weeks.
●     Mass Customization-Individually customized products produced on a mass scale. Cars with weather equipment for your local neighborhood; VCRs preprogrammed to your habits. All products are manufactured to personal specifications, but at mass production prices.
●     Industrial Ecology-Closed-loop, no-waste, zero-pollution manufacturing; products designed for disassembly; and a gradual shift to biologically compatible techniques. Increasing intolerance for 
transgressions against the rule of biology.
●     Global Accounting-Even small businesses become global in perspective. Unexploited, undeveloped economic "frontiers" disappear geographically. The game shifts from zero-sum, where every win means someone else's loss, to positive-sum, where the economic rewards go to those able play the system as a unified whole. Alliances, partnerships, collaboration, even if temporary or paradoxical, become essential and the norm.
●     Coevolved Customers-Customers are trained and educated by the company, and then the company is trained and educated by the customer. Products in a network culture become updatable franchises that coevolve in continuous improvement with customer use. Think software updates and subscriptions. Companies become clubs or user groups of coevolving customers. A company cannot be a learning company without also being a teaching company.
●     Knowledge Based-Networked data makes any job faster, better, easier. But data is cheap, and in the large volumes on networks, a nuisance. The advantage no longer lies in "how you do a job" but in "which job do you do?" Data can't tell you that; knowledge does. Coordination of data into knowledge becomes priceless.
●     Free Bandwidth-Connecting is free; switching is expensive. You can send anyone anything anytime; but choosing who, what, and when to send, or what and when to get is the trick. Selecting what not to connect to is key.
●     Increasing Returns-Them that has, gets. Them that gives away and shares, gets. Being early counts. A network's value grows faster than the number of members added to it. A 10 percent increase in customers for a company in a nonnetworked economy may increase its revenue 10 percent. But adding 10 percent more customers to a networked company, such as a telephone company, could increase revenues by 20 percent because of the exponentially greater numbers of conversations between each member, both new and old.
●     Digital Money-Everyday digital cash replaces batch-mode paper money. All accounts become real-time. 
●     Underwire Economies-The dark side: the informal economy booms. Creative edges and fringe areas expand, but now they are invisibly connected on encrypted networks. Distributed cores and electronic money drives economic activity underwire.
In network economics the customer can expect increased speed and choice, and more responsibility as a customer. The provider can expect increased 
decentralization of all functions and increased symbiotic relationships with customers. Finding the right customer in the chaotic web of infinite communications will be a new game.
The central act of the coming era is to connect everything to everything. All 
matter, big and small, will be linked into vast webs of networks at many levels. Without grand meshes there is no life, intelligence, and evolution; with networks there are all of these and more. 
My friend Barlow-at least Barlow's disembodied voice-has already connected 
his everything to his everything. He lives and works in a true network economy. He gives away information-for free-and he is given money. The more he gives away, the more money he gets. He had something to say about the emerging network in an e-mail message to me: 
Computers-the gizmos themselves-have far less to do with techie enthusiasm than some half-understood resonance to The Great Work: hardwiring collective consciousness, creating the Planetary Mind. Teilhard de Chardin wrote about this enterprise many years ago and would be appalled by the prosaic nature of the tools we will use to bring it about. But I think there is something sweetly ironic that the ladder to his Omega Point might be built by engineers and not mystics.
The boldest scientists, technologists, economists, and philosophers of this day have taken the first steps to interconnect all things and all events into a vast complex web. As very large webs penetrate the made world, we see the first glimpses of what emerges from that net-machines that become alive, smart, and evolve-a neo-biological civilization.
There is a sense in which a global mind also emerges in a network culture. 
The global mind is the union of computer and nature-of telephones and human brains and more. It is a very large complexity of indeterminate shape governed by an invisible hand of its own. We humans will be unconscious of what the global mind ponders. This is not because we are not smart enough, but because the design of a mind does not allow the parts to understand the whole. The particular thoughts of the global mind-and its subsequent actions-will be out of our control and beyond our understanding. Thus network economics will breed a new spiritualism. 
Our primary difficulty in comprehending the global mind of a network culture 
will be that it does not have a central "I" to appeal to. No headquarters, no head. That will be most exasperating and discouraging. In the past, adventurous men have sought the holy grail, or the source of the Nile, or Prester John, or the secrets of the pyramids. In the future the quest will be to find the "I am" of the global mind, the source of its coherence. Many souls will lose all they have searching for it-and many will be the theories of where the global mind's "I am" hides. But it will be a never-ending quest like the 
others before it.